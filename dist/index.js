/**
 * Copyright Metrichor Ltd. (An Oxford Nanopore Technologies Company) 2020
 */

"use strict";function e(e){return e&&"object"===typeof e&&"default"in e?e.default:e}var t=e(require("aws-sdk")),s=e(require("fs-extra")),i=require("lodash"),o=require("os"),r=e(o),n=e(require("path")),a=e(require("sqlite")),l=e(require("axios")),c=e(require("crypto")),h=require("tunnel"),u=require("rxjs"),p=e(require("graphql-tag")),d=require("apollo-cache-inmemory"),g=e(require("apollo-client")),f=require("apollo-link"),m=require("apollo-link-http"),w=require("@lifeomic/axios-fetch"),y=e(require("socket.io-client")),k=require("zlib"),v=e(k),S=e(require("fdir")),b=e(require("proxy-agent")),$=e(require("readline")),I="undefined"!==typeof globalThis?globalThis:"undefined"!==typeof window?window:"undefined"!==typeof global?global:"undefined"!==typeof self?self:{};function _(e,t,s){return e(s={path:t,exports:{},require:function(e,t){return function(){throw new Error("Dynamic requires are not currently supported by @rollup/plugin-commonjs")}((void 0===t||null===t)&&s.path)}},s.exports),s.exports}var E=_((function(e,t){!function(s){var i=t&&!t.nodeType&&t,o=e&&!e.nodeType&&e,r="object"==typeof I&&I;r.global!==r&&r.window!==r&&r.self!==r||(s=r);var n,a,l=2147483647,c=/^xn--/,h=/[^\x20-\x7E]/,u=/[\x2E\u3002\uFF0E\uFF61]/g,p={overflow:"Overflow: input needs wider integers to process","not-basic":"Illegal input >= 0x80 (not a basic code point)","invalid-input":"Invalid input"},d=Math.floor,g=String.fromCharCode;function f(e){throw RangeError(p[e])}function m(e,t){for(var s=e.length,i=[];s--;)i[s]=t(e[s]);return i}function w(e,t){var s=e.split("@"),i="";return s.length>1&&(i=s[0]+"@",e=s[1]),i+m((e=e.replace(u,".")).split("."),t).join(".")}function y(e){for(var t,s,i=[],o=0,r=e.length;o<r;)(t=e.charCodeAt(o++))>=55296&&t<=56319&&o<r?56320==(64512&(s=e.charCodeAt(o++)))?i.push(((1023&t)<<10)+(1023&s)+65536):(i.push(t),o--):i.push(t);return i}function k(e){return m(e,(function(e){var t="";return e>65535&&(t+=g((e-=65536)>>>10&1023|55296),e=56320|1023&e),t+=g(e)})).join("")}function v(e,t){return e+22+75*(e<26)-((0!=t)<<5)}function S(e,t,s){var i=0;for(e=s?d(e/700):e>>1,e+=d(e/t);e>455;i+=36)e=d(e/35);return d(i+36*e/(e+38))}function b(e){var t,s,i,o,r,n,a,c,h,u,p,g=[],m=e.length,w=0,y=128,v=72;for((s=e.lastIndexOf("-"))<0&&(s=0),i=0;i<s;++i)e.charCodeAt(i)>=128&&f("not-basic"),g.push(e.charCodeAt(i));for(o=s>0?s+1:0;o<m;){for(r=w,n=1,a=36;o>=m&&f("invalid-input"),((c=(p=e.charCodeAt(o++))-48<10?p-22:p-65<26?p-65:p-97<26?p-97:36)>=36||c>d((l-w)/n))&&f("overflow"),w+=c*n,!(c<(h=a<=v?1:a>=v+26?26:a-v));a+=36)n>d(l/(u=36-h))&&f("overflow"),n*=u;v=S(w-r,t=g.length+1,0==r),d(w/t)>l-y&&f("overflow"),y+=d(w/t),w%=t,g.splice(w++,0,y)}return k(g)}function $(e){var t,s,i,o,r,n,a,c,h,u,p,m,w,k,b,$=[];for(m=(e=y(e)).length,t=128,s=0,r=72,n=0;n<m;++n)(p=e[n])<128&&$.push(g(p));for(i=o=$.length,o&&$.push("-");i<m;){for(a=l,n=0;n<m;++n)(p=e[n])>=t&&p<a&&(a=p);for(a-t>d((l-s)/(w=i+1))&&f("overflow"),s+=(a-t)*w,t=a,n=0;n<m;++n)if((p=e[n])<t&&++s>l&&f("overflow"),p==t){for(c=s,h=36;!(c<(u=h<=r?1:h>=r+26?26:h-r));h+=36)b=c-u,k=36-u,$.push(g(v(u+b%k,0))),c=d(b/k);$.push(g(v(c,0))),r=S(s,w,i==o),s=0,++i}++s,++t}return $.join("")}if(n={version:"1.3.2",ucs2:{decode:y,encode:k},decode:b,encode:$,toASCII:function(e){return w(e,(function(e){return h.test(e)?"xn--"+$(e):e}))},toUnicode:function(e){return w(e,(function(e){return c.test(e)?b(e.slice(4).toLowerCase()):e}))}},i&&o)if(e.exports==i)o.exports=n;else for(a in n)n.hasOwnProperty(a)&&(i[a]=n[a]);else s.punycode=n}(I)}));function P(e,t){return Object.prototype.hasOwnProperty.call(e,t)}var T=function(e,t,s,i){t=t||"&",s=s||"=";var o={};if("string"!==typeof e||0===e.length)return o;var r=/\+/g;e=e.split(t);var n=1e3;i&&"number"===typeof i.maxKeys&&(n=i.maxKeys);var a=e.length;n>0&&a>n&&(a=n);for(var l=0;l<a;++l){var c,h,u,p,d=e[l].replace(r,"%20"),g=d.indexOf(s);g>=0?(c=d.substr(0,g),h=d.substr(g+1)):(c=d,h=""),u=decodeURIComponent(c),p=decodeURIComponent(h),P(o,u)?Array.isArray(o[u])?o[u].push(p):o[u]=[o[u],p]:o[u]=p}return o},j=function(e){switch(typeof e){case"string":return e;case"boolean":return e?"true":"false";case"number":return isFinite(e)?e:"";default:return""}},x=function(e,t,s,i){return t=t||"&",s=s||"=",null===e&&(e=void 0),"object"===typeof e?Object.keys(e).map((function(i){var o=encodeURIComponent(j(i))+s;return Array.isArray(e[i])?e[i].map((function(e){return o+encodeURIComponent(j(e))})).join(t):o+encodeURIComponent(j(e[i]))})).join(t):i?encodeURIComponent(j(i))+s+encodeURIComponent(j(e)):""},O=_((function(e,t){t.decode=t.parse=T,t.encode=t.stringify=x})),R=function(e,t){return H(e,!1,!0).resolve(t)};function q(){this.protocol=null,this.slashes=null,this.auth=null,this.host=null,this.port=null,this.hostname=null,this.hash=null,this.search=null,this.query=null,this.pathname=null,this.path=null,this.href=null}var N=/^([a-z0-9.+-]+:)/i,C=/:[0-9]*$/,A=["{","}","|","\\","^","`"].concat(["<",">",'"',"`"," ","\r","\n","\t"]),M=["'"].concat(A),F=["%","/","?",";","#"].concat(M),W=["/","?","#"],D=/^[a-z0-9A-Z_-]{0,63}$/,Q=/^([a-z0-9A-Z_-]{0,63})(.*)$/,U={javascript:!0,"javascript:":!0},z={javascript:!0,"javascript:":!0},L={http:!0,https:!0,ftp:!0,gopher:!0,file:!0,"http:":!0,"https:":!0,"ftp:":!0,"gopher:":!0,"file:":!0};function H(e,t,s){if(e&&G(e)&&e instanceof q)return e;var i=new q;return i.parse(e,t,s),i}function J(e){return"string"===typeof e}function G(e){return"object"===typeof e&&null!==e}function B(e){return null===e}q.prototype.parse=function(e,t,s){if(!J(e))throw new TypeError("Parameter 'url' must be a string, not "+typeof e);var i=e;i=i.trim();var o=N.exec(i);if(o){var r=(o=o[0]).toLowerCase();this.protocol=r,i=i.substr(o.length)}if(s||o||i.match(/^\/\/[^@\/]+@[^@\/]+/)){var n="//"===i.substr(0,2);!n||o&&z[o]||(i=i.substr(2),this.slashes=!0)}if(!z[o]&&(n||o&&!L[o])){for(var a,l,c=-1,h=0;h<W.length;h++){-1!==(u=i.indexOf(W[h]))&&(-1===c||u<c)&&(c=u)}-1!==(l=-1===c?i.lastIndexOf("@"):i.lastIndexOf("@",c))&&(a=i.slice(0,l),i=i.slice(l+1),this.auth=decodeURIComponent(a)),c=-1;for(h=0;h<F.length;h++){var u;-1!==(u=i.indexOf(F[h]))&&(-1===c||u<c)&&(c=u)}-1===c&&(c=i.length),this.host=i.slice(0,c),i=i.slice(c),this.parseHost(),this.hostname=this.hostname||"";var p="["===this.hostname[0]&&"]"===this.hostname[this.hostname.length-1];if(!p)for(var d=this.hostname.split(/\./),g=(h=0,d.length);h<g;h++){var f=d[h];if(f&&!f.match(D)){for(var m="",w=0,y=f.length;w<y;w++)f.charCodeAt(w)>127?m+="x":m+=f[w];if(!m.match(D)){var k=d.slice(0,h),v=d.slice(h+1),S=f.match(Q);S&&(k.push(S[1]),v.unshift(S[2])),v.length&&(i="/"+v.join(".")+i),this.hostname=k.join(".");break}}}if(this.hostname.length>255?this.hostname="":this.hostname=this.hostname.toLowerCase(),!p){var b=this.hostname.split("."),$=[];for(h=0;h<b.length;++h){var I=b[h];$.push(I.match(/[^A-Za-z0-9_-]/)?"xn--"+E.encode(I):I)}this.hostname=$.join(".")}var _=this.port?":"+this.port:"",P=this.hostname||"";this.host=P+_,this.href+=this.host,p&&(this.hostname=this.hostname.substr(1,this.hostname.length-2),"/"!==i[0]&&(i="/"+i))}if(!U[r])for(h=0,g=M.length;h<g;h++){var T=M[h],j=encodeURIComponent(T);j===T&&(j=escape(T)),i=i.split(T).join(j)}var x=i.indexOf("#");-1!==x&&(this.hash=i.substr(x),i=i.slice(0,x));var R=i.indexOf("?");if(-1!==R?(this.search=i.substr(R),this.query=i.substr(R+1),t&&(this.query=O.parse(this.query)),i=i.slice(0,R)):t&&(this.search="",this.query={}),i&&(this.pathname=i),L[r]&&this.hostname&&!this.pathname&&(this.pathname="/"),this.pathname||this.search){_=this.pathname||"",I=this.search||"";this.path=_+I}return this.href=this.format(),this},q.prototype.format=function(){var e=this.auth||"";e&&(e=(e=encodeURIComponent(e)).replace(/%3A/i,":"),e+="@");var t=this.protocol||"",s=this.pathname||"",i=this.hash||"",o=!1,r="";this.host?o=e+this.host:this.hostname&&(o=e+(-1===this.hostname.indexOf(":")?this.hostname:"["+this.hostname+"]"),this.port&&(o+=":"+this.port)),this.query&&G(this.query)&&Object.keys(this.query).length&&(r=O.stringify(this.query));var n=this.search||r&&"?"+r||"";return t&&":"!==t.substr(-1)&&(t+=":"),this.slashes||(!t||L[t])&&!1!==o?(o="//"+(o||""),s&&"/"!==s.charAt(0)&&(s="/"+s)):o||(o=""),i&&"#"!==i.charAt(0)&&(i="#"+i),n&&"?"!==n.charAt(0)&&(n="?"+n),t+o+(s=s.replace(/[?#]/g,(function(e){return encodeURIComponent(e)})))+(n=n.replace("#","%23"))+i},q.prototype.resolve=function(e){return this.resolveObject(H(e,!1,!0)).format()},q.prototype.resolveObject=function(e){if(J(e)){var t=new q;t.parse(e,!1,!0),e=t}var s=new q;if(Object.keys(this).forEach((function(e){s[e]=this[e]}),this),s.hash=e.hash,""===e.href)return s.href=s.format(),s;if(e.slashes&&!e.protocol)return Object.keys(e).forEach((function(t){"protocol"!==t&&(s[t]=e[t])})),L[s.protocol]&&s.hostname&&!s.pathname&&(s.path=s.pathname="/"),s.href=s.format(),s;if(e.protocol&&e.protocol!==s.protocol){if(!L[e.protocol])return Object.keys(e).forEach((function(t){s[t]=e[t]})),s.href=s.format(),s;if(s.protocol=e.protocol,e.host||z[e.protocol])s.pathname=e.pathname;else{for(var i=(e.pathname||"").split("/");i.length&&!(e.host=i.shift()););e.host||(e.host=""),e.hostname||(e.hostname=""),""!==i[0]&&i.unshift(""),i.length<2&&i.unshift(""),s.pathname=i.join("/")}if(s.search=e.search,s.query=e.query,s.host=e.host||"",s.auth=e.auth,s.hostname=e.hostname||e.host,s.port=e.port,s.pathname||s.search){var o=s.pathname||"",r=s.search||"";s.path=o+r}return s.slashes=s.slashes||e.slashes,s.href=s.format(),s}var n=s.pathname&&"/"===s.pathname.charAt(0),a=e.host||e.pathname&&"/"===e.pathname.charAt(0),l=a||n||s.host&&e.pathname,c=l,h=s.pathname&&s.pathname.split("/")||[],u=(i=e.pathname&&e.pathname.split("/")||[],s.protocol&&!L[s.protocol]);if(u&&(s.hostname="",s.port=null,s.host&&(""===h[0]?h[0]=s.host:h.unshift(s.host)),s.host="",e.protocol&&(e.hostname=null,e.port=null,e.host&&(""===i[0]?i[0]=e.host:i.unshift(e.host)),e.host=null),l=l&&(""===i[0]||""===h[0])),a)s.host=e.host||""===e.host?e.host:s.host,s.hostname=e.hostname||""===e.hostname?e.hostname:s.hostname,s.search=e.search,s.query=e.query,h=i;else if(i.length)h||(h=[]),h.pop(),h=h.concat(i),s.search=e.search,s.query=e.query;else if(null!=e.search){if(u)s.hostname=s.host=h.shift(),(m=!!(s.host&&s.host.indexOf("@")>0)&&s.host.split("@"))&&(s.auth=m.shift(),s.host=s.hostname=m.shift());return s.search=e.search,s.query=e.query,B(s.pathname)&&B(s.search)||(s.path=(s.pathname?s.pathname:"")+(s.search?s.search:"")),s.href=s.format(),s}if(!h.length)return s.pathname=null,s.search?s.path="/"+s.search:s.path=null,s.href=s.format(),s;for(var p=h.slice(-1)[0],d=(s.host||e.host)&&("."===p||".."===p)||""===p,g=0,f=h.length;f>=0;f--)"."==(p=h[f])?h.splice(f,1):".."===p?(h.splice(f,1),g++):g&&(h.splice(f,1),g--);if(!l&&!c)for(;g--;g)h.unshift("..");!l||""===h[0]||h[0]&&"/"===h[0].charAt(0)||h.unshift(""),d&&"/"!==h.join("/").substr(-1)&&h.push("");var m,w=""===h[0]||h[0]&&"/"===h[0].charAt(0);u&&(s.hostname=s.host=w?"":h.length?h.shift():"",(m=!!(s.host&&s.host.indexOf("@")>0)&&s.host.split("@"))&&(s.auth=m.shift(),s.host=s.hostname=m.shift()));return(l=l||s.host&&h.length)&&!w&&h.unshift(""),h.length?s.pathname=h.join("/"):(s.pathname=null,s.path=null),B(s.pathname)&&B(s.search)||(s.path=(s.pathname?s.pathname:"")+(s.search?s.search:"")),s.auth=e.auth||s.auth,s.slashes=s.slashes||e.slashes,s.href=s.format(),s},q.prototype.parseHost=function(){var e=this.host,t=C.exec(e);t&&(":"!==(t=t[0])&&(this.port=t.substr(1)),e=e.substr(0,e.length-t.length)),e&&(this.hostname=e)};var V="3.0.926";l.defaults.validateStatus=e=>e<=504;const K=function(){const e=(e,t)=>{e.headers||(e.headers={});let s=t;if(s||(s={}),!s.apikey)return;if(e.headers["X-EPI2ME-ApiKey"]=s.apikey,!s.apisecret)return;e.headers["X-EPI2ME-SignatureDate"]=(new Date).toISOString(),e.url.match(/^https:/)&&(e.url=e.url.replace(/:443/,"")),e.url.match(/^http:/)&&(e.url=e.url.replace(/:80/,""));const i=[e.url,Object.keys(e.headers).sort().filter(e=>e.match(/^x-epi2me/i)).map(t=>`${t}:${e.headers[t]}`).join("\n")].join("\n"),o=c.createHmac("sha1",s.apisecret).update(i).digest("hex");e.headers["X-EPI2ME-SignatureV0"]=o},t=async e=>{const t=e?e.data:null;if(!t)return Promise.reject(new Error("unexpected non-json response"));if(e&&e.status>=400){let s=`Network error ${e.status}`;return t.error&&(s=t.error),504===e.status&&(s="Please check your network connection and try again."),Promise.reject(new Error(s))}return t.error?Promise.reject(new Error(t.error)):Promise.resolve(t)};return{version:"3.0.926",headers:(t,s)=>{const{log:o}=i.merge({log:{debug:()=>{}}},s);let r=s;if(r||(r={}),t.headers=i.merge({Accept:"application/json","Content-Type":"application/json","X-EPI2ME-Client":r.user_agent||"api","X-EPI2ME-Version":r.agent_version||K.version},t.headers,r.headers),"signing"in r&&!r.signing||e(t,r),r.proxy){const e=r.proxy.match(/https?:\/\/((\S+):(\S+)@)?(\S+):(\d+)/),s=e[2],i=e[3],n={host:e[4],port:e[5]};s&&i&&(n.proxyAuth=`${s}:${i}`),r.proxy.match(/^https/)?(o.debug("using HTTPS over HTTPS proxy",JSON.stringify(n)),t.httpsAgent=h.httpsOverHttps({proxy:n})):(o.debug("using HTTPS over HTTP proxy",JSON.stringify(n)),t.httpsAgent=h.httpsOverHttp({proxy:n})),t.proxy=!1}},head:async(e,t)=>{const{log:s}=i.merge({log:{debug:()=>{}}},t);let o,r=t.url,n=e;t.skip_url_mangle?o=n:(n=`/${n}`,r=r.replace(/\/+$/,""),n=n.replace(/\/+/g,"/"),o=r+n);const a={url:o,gzip:!0};let c;K.headers(a,t);try{if(s.debug(`HEAD ${a.url}`),c=await l.head(a.url,a),c&&c.status>=400){let e=`Network error ${c.status}`;return 504===c.status&&(e="Please check your network connection and try again."),Promise.reject(new Error(e))}}catch(h){return Promise.reject(h)}return Promise.resolve(c)},get:async(e,s)=>{const{log:o}=i.merge({log:{debug:()=>{}}},s);let r,n=s.url,a=e;s.skip_url_mangle?r=a:(a=`/${a}`,n=n.replace(/\/+$/,""),a=a.replace(/\/+/g,"/"),r=n+a);const c={url:r,gzip:!0};let h;K.headers(c,s);try{o.debug(`GET ${c.url}`),h=await l.get(c.url,c)}catch(u){return Promise.reject(u)}return t(h,s)},post:async(e,s,o)=>{const{log:r}=i.merge({log:{debug:()=>{}}},o);let n=o.url;n=n.replace(/\/+$/,"");const a={url:`${n}/${e.replace(/\/+/g,"/")}`,gzip:!0,data:s,headers:{}};if(o.legacy_form){const e=[],t=i.merge({json:JSON.stringify(s)},s);Object.keys(t).sort().forEach(s=>{e.push(`${s}=${escape(t[s])}`)}),a.data=e.join("&"),a.headers["Content-Type"]="application/x-www-form-urlencoded"}K.headers(a,o);const{data:c}=a;let h;delete a.data;try{r.debug(`POST ${a.url}`),h=await l.post(a.url,c,a)}catch(u){return Promise.reject(u)}return o.handler?o.handler(h):t(h,o)},put:async(e,s,o,r)=>{const{log:n}=i.merge({log:{debug:()=>{}}},r);let a=r.url;a=a.replace(/\/+$/,"");const c={url:`${a}/${e.replace(/\/+/g,"/")}/${s}`,gzip:!0,data:o,headers:{}};if(r.legacy_form){const e=[],t=i.merge({json:JSON.stringify(o)},o);Object.keys(t).sort().forEach(s=>{e.push(`${s}=${escape(t[s])}`)}),c.data=e.join("&"),c.headers["Content-Type"]="application/x-www-form-urlencoded"}K.headers(c,r);const{data:h}=c;let u;delete c.data;try{n.debug(`PUT ${c.url}`),u=await l.put(c.url,h,c)}catch(p){return Promise.reject(p)}return t(u,r)},convertResponseToObject(e){if("object"===typeof e)return e;try{return JSON.parse(e)}catch(t){throw new Error(`exception parsing chain JSON ${String(t)}`)}}}}();K.pipe=async(e,t,i,o)=>{let r=i.url,n=`/${e}`;r=r.replace(/\/+$/,""),n=n.replace(/\/+/g,"/");const a={url:r+n,gzip:!0,headers:{"Accept-Encoding":"gzip",Accept:"application/gzip"}};return K.headers(a,i),i.proxy&&(a.proxy=i.proxy),o&&(a.onUploadProgress=o),a.responseType="stream",new Promise((e,i)=>{l.get(a.url,a).then(o=>{const r=s.createWriteStream(t);o.data.pipe(r),r.on("finish",()=>{e(t)}),r.on("error",e=>{i(new Error(`writer failed ${String(e)}`))})}).catch(e=>{i(e)})})};let X=0;K.getFileID=()=>(X+=1,`FILE_${X}`),K.lsRecursive=async(e,t,o)=>{let r=e;const a=s.statSync(t);if(o){if(await o(t,a))return[]}return a.isDirectory()?s.readdir(t).then(e=>e.map(e=>n.join(t,e))).then(e=>Promise.all(e.map(e=>K.lsRecursive(r,e,o)))).then(e=>i.flatten(e)):(a.isFile()&&r===t&&(r=n.dirname(t)),[{name:n.parse(t).base,path:t,relative:t.replace(r,""),size:a.size,id:K.getFileID()}])},K.loadInputFiles=async({inputFolders:e,outputFolder:t,filetype:s},i,o)=>{let r=s;r instanceof Array||(r=[r]),r=r.map(e=>e&&0!==e.indexOf(".")?`.${e}`:e);const a=async(e,s)=>{const i=n.basename(e),a=[new Promise((t,s)=>"downloads"===i||"skip"===i||"fail"===i||"fastq_fail"===i||"tmp"===i?s(new Error(`${e} failed basic filename`)):t("basic ok")),new Promise((o,a)=>{const l=r.length?new RegExp(`(?:${r.join("|")})$`):null;return e.split(n.sep).filter(e=>e.match(/^[.]/)).length||t&&i===n.basename(t)||l&&!e.match(l)&&s.isFile()?a(new Error(`${e} failed extended filename`)):o("extended ok")}),o?new Promise((t,s)=>{o(e).then(i=>i?s(new Error(`${e} failed extraFilter`)):t("extra ok"))}):Promise.resolve("extra skip")];return Promise.all(a).then(()=>null).catch(()=>"exclude")};return(await Promise.all(e.map(e=>K.lsRecursive(e,e,a)))).reduce((e,t)=>[...e,...t.filter(e=>!!e)],[])},K.stripFile=e=>[n.dirname(e),n.basename(e)];class Y{constructor(e,t,o){const r=i.merge({},t);this.options=r,this.log=o;const{idWorkflowInstance:l,inputFolders:c}=r;o.debug(`setting up ${e}/db.sqlite for ${l}`),this.db=s.mkdirp(e).then(()=>(this.log.debug(`opening ${e}/db.sqlite`),a.open(n.join(e,"db.sqlite")).then(async t=>{this.log.debug(`opened ${e}/db.sqlite`),await t.migrate({migrationsPath:n.join(__dirname,"migrations")});const s=c.map(()=>"(?)").join(",");try{return await Promise.all([t.run("INSERT INTO meta (version, idWorkflowInstance) VALUES(?, ?)",V,l),t.run(`INSERT INTO folders (folder_path) VALUES ${s}`,c)]),Promise.resolve(t)}catch(i){return this.log.error(i),Promise.reject(i)}}))).catch(e=>{throw this.log.error(e),e})}async uploadFile(e){const t=await this.db,[s,i]=K.stripFile(e);return await t.run("INSERT OR IGNORE INTO folders (folder_path) VALUES (?)",s),t.run("INSERT INTO uploads(filename, path_id) VALUES(?, (SELECT folder_id FROM folders WHERE folder_path = ?))",i,s)}async skipFile(e){const t=await this.db,[s,i]=K.stripFile(e);return await t.run("INSERT OR IGNORE INTO folders (folder_path) VALUES (?)",s),t.run("INSERT INTO skips(filename, path_id) VALUES(?, (SELECT folder_id FROM folders WHERE folder_path = ?))",i,s)}async splitFile(e,t){const s=await this.db,[i,o]=K.stripFile(e),r=K.stripFile(t)[1];return await s.run("INSERT OR IGNORE INTO folders (folder_path) VALUES (?)",i),s.run("INSERT INTO splits(filename, parent, child_path_id, start, end) VALUES(?, ?, (SELECT folder_id FROM folders WHERE folder_path = ?), CURRENT_TIMESTAMP, NULL)",o,r,i)}async splitDone(e){const t=await this.db,[s,i]=K.stripFile(e);return t.run("UPDATE splits SET end=CURRENT_TIMESTAMP WHERE filename=? AND child_path_id=(SELECT folder_id FROM folders WHERE folder_path=?)",i,s)}async splitClean(){return(await this.db).all("SELECT splits.filename, folders.folder_path FROM splits INNER JOIN folders ON folders.folder_id = splits.child_path_id WHERE end IS NULL").then(e=>{if(!e)return this.log.info("no split files to clean"),Promise.resolve([]);this.log.info(`cleaning ${e.length} split files`),this.log.debug(`going to clean: ${e.map(e=>e.filename).join(" ")}`);const t=e.map(e=>s.unlink(n.join(e.folder_path,e.filename)).catch(()=>{console.warn(`Failed to cleanup ${n.join(e.folder_path,e.filename)}`)}));return Promise.all(t)})}async seenUpload(e){const t=await this.db,[s,o]=K.stripFile(e);return Promise.all([t.get("SELECT * FROM uploads u INNER JOIN folders ON folders.folder_id = u.path_id WHERE u.filename=? AND folders.folder_path=? LIMIT 1",[o,s]),t.get("SELECT * FROM skips s INNER JOIN folders ON folders.folder_id = s.path_id WHERE s.filename=? AND folders.folder_path=? LIMIT 1",o,s)]).then(e=>i.remove(e,void 0).length)}}var Z="https://epi2me.nanoporetech.com",ee={local:!1,url:Z,user_agent:"EPI2ME API",region:"eu-west-1",sessionGrace:5,uploadTimeout:1200,downloadTimeout:1200,fileCheckInterval:5,downloadCheckInterval:3,stateCheckInterval:60,inFlightDelay:600,waitTimeSeconds:20,waitTokenError:30,transferPoolSize:3,downloadMode:"data+telemetry",filetype:[".fastq",".fq",".fastq.gz",".fq.gz"],signing:!0,sampleDirectory:"/data"};const te="\npage\npages\nhasNext\nhasPrevious\ntotalCount\n",se="\nidWorkflowInstance\nstartDate\nworkflowImage{\n  workflow\n  {\n    rev\n    name\n  }\n}\n",ie=function(){const e=(e,t)=>{e.headers||(e.headers={});let s=t;if(s||(s={}),!s.apikey||!s.apisecret)return;e.headers["X-EPI2ME-APIKEY"]=s.apikey,e.headers["X-EPI2ME-SIGNATUREDATE"]=(new Date).toISOString();const i=[Object.keys(e.headers).sort().filter(e=>e.match(/^x-epi2me/i)).map(t=>`${t}:${e.headers[t]}`).join("\n"),e.body].join("\n"),o=c.createHmac("sha1",s.apisecret).update(i).digest("hex");e.headers["X-EPI2ME-SIGNATUREV0"]=o};return{version:"3.0.926",setHeaders:(t,s)=>{const{log:o}=i.merge({log:{debug:()=>{}}},s);let r=s;if(r||(r={}),t.headers=i.merge({Accept:"application/json","Content-Type":"application/json","X-EPI2ME-CLIENT":r.user_agent||"api","X-EPI2ME-VERSION":r.agent_version||ie.version},t.headers,r.headers),"signing"in r&&!r.signing||e(t,r),r.proxy){const e=r.proxy.match(/https?:\/\/((\S+):(\S+)@)?(\S+):(\d+)/),s=e[2],i=e[3],n={host:e[4],port:e[5]};s&&i&&(n.proxyAuth=`${s}:${i}`),r.proxy.match(/^https/)?(o.debug("using HTTPS over HTTPS proxy",JSON.stringify(n)),t.httpsAgent=h.httpsOverHttps({proxy:n})):(o.debug("using HTTPS over HTTP proxy",JSON.stringify(n)),t.httpsAgent=h.httpsOverHttp({proxy:n})),t.proxy=!1}}}}(),oe=w.buildAxiosFetch(l),re=(e,t)=>{const{apikey:s,apisecret:i}=t.headers.keys;return delete t.headers.keys,ie.setHeaders(t,{apikey:s,apisecret:i,signing:!0}),oe(e,t)},ne=new g({link:new f.ApolloLink(e=>{const{apikey:t,apisecret:s,url:i}=e.getContext(),o=m.createHttpLink({uri:R(i,"/graphql"),fetch:re,headers:{keys:{apikey:t,apisecret:s}}});return f.execute(o,e)}),cache:new d.InMemoryCache});class ae{constructor(e){this.createContext=e=>{const{apikey:t,apisecret:s,url:o}=this.options;return i.merge({apikey:t,apisecret:s,url:o},e)},this.query=e=>({context:t={},variables:s={},options:i={}}={})=>{const o=this.createContext(t);let r;return r="string"===typeof e?p`
        ${e}
      `:"function"===typeof e?p`
        ${e(te)}
      `:e,this.client.query(Object.assign(Object.assign({query:r,variables:s},i),{context:o}))},this.mutate=e=>({context:t={},variables:s={},options:i={}}={})=>{const o=this.createContext(t);let r;return r="string"===typeof e?p`
        ${e}
      `:e,this.client.mutate(Object.assign(Object.assign({mutation:r,variables:s},i),{context:o}))},this.resetCache=()=>{this.client.resetStore()},this.workflows=this.query(p`
    query allWorkflows($page: Int, $pageSize: Int, $isActive: Int, $orderBy: String, $region: String) {
      allWorkflows(page: $page, pageSize: $pageSize, isActive: $isActive, orderBy: $orderBy, region: $region) {
        ${te}
        results {
          ${"\nidWorkflow\nname\ndescription\nsummary\nrev\n"}
        }
      }
    }
  `),this.workflowPages=async e=>{let t=e,s=await this.workflows({variables:{page:t}});const i=async e=>(t=e,s=await this.workflows({variables:{page:t}}),s);return{data:s,next:()=>i(t+1),previous:()=>i(t-1),first:()=>i(1),last:()=>i(0)}},this.workflow=this.query(p`
    query workflow($idWorkflow: ID!) {
      workflow(idWorkflow: $idWorkflow) {
        ${"\nidWorkflow\nname\ndescription\nsummary\nrev\n"}
      }
    }
   `),this.workflowInstances=this.query(p`
  query allWorkflowInstances($page: Int, $pageSize: Int, $shared: Boolean, $idUser: ID, $orderBy: String) {
    allWorkflowInstances(page: $page, pageSize: $pageSize, shared: $shared, idUser: $idUser, orderBy: $orderBy) {
      ${te}
      results {
        ${se}
      }
    }
  }
   `),this.workflowInstance=this.query(p`
      query workflowInstance($idWorkflowInstance: ID!) {
        workflowInstance(idWorkflowInstance: $idWorkflowInstance) {
          ${se}
        }
      }
   `),this.startWorkflow=this.mutate(p`
    mutation startWorkflow(
      $idWorkflow: ID!
      $computeAccountId: ID!
      $storageAccountId: ID
      $isConsentedHuman: Boolean = false
      $idDataset: ID
      $storeResults: Boolean = false
      $userDefined: GenericScalar
      $instanceAttributes: [GenericScalar]
      $region: String
    ) {
      startData: startWorkflowInstance(
        idWorkflow: $idWorkflow
        computeAccountId: $computeAccountId
        storageAccountId: $storageAccountId
        isConsentedHuman: $isConsentedHuman
        idDataset: $idDataset
        storeResults: $storeResults
        userDefined: $userDefined
        instanceAttributes: $instanceAttributes
        region: $region
      ) {
        bucket
        idUser
        remoteAddr
        instance {
          idWorkflowInstance
          chain
          keyId
          outputqueue
          mappedTelemetry
          workflowImage {
            inputqueue
            workflow {
              idWorkflow
            }
            region {
              name
            }
          }
        }
      }
    }
  `),this.stopWorkflow=this.mutate(p`
    mutation stopWorkflowInstance($idWorkflowInstance: ID!) {
      stopData: stopWorkflowInstance(idWorkflowInstance: $idWorkflowInstance) {
        success
        message
      }
    }
  `),this.instanceToken=this.mutate(p`
    mutation getInstanceToken($idWorkflowInstance: ID!) {
      token: getInstanceToken(idWorkflowInstance: $idWorkflowInstance) {
        id_workflow_instance: idWorkflowInstance
        accessKeyId
        secretAccessKey
        sessionToken
        expiration
        region
      }
    }
  `),this.user=this.query(p`
    query user {
      me {
        username
        realname
        useraccountSet {
          idUserAccount
        }
      }
    }
  `),this.updateUser=this.mutate(p`
    mutation updateUser($idRegionPreferred: ID!) {
      updateUser(idRegionPreferred: $idRegionPreferred) {
        idRegionPreferred
      }
    }
  `),this.register=this.mutate(p`
    mutation registerToken($code: String!, $description: String) {
      registerToken(code: $code, description: $description) {
        apikey
        apisecret
        description
      }
    }
  `),this.status=this.query(p`
    query status {
      status {
        portalVersion
        remoteAddr
        serverTime
        minimumAgent
        dbVersion
      }
    }
  `),this.healthCheck=()=>K.get("/status",Object.assign(Object.assign({},this.options),{log:{debug:()=>{}}})),this.regions=this.query(p`
    query regions {
      regions {
        idRegion
        description
        name
      }
    }
  `),this.options=i.assign({agent_version:K.version,local:!1,url:Z,user_agent:"EPI2ME API",signing:!0},e),this.options.url=this.options.url.replace(/:\/\//,"://graphql."),this.options.url=this.options.url.replace(/\/$/,""),this.log=this.options.log,this.client=ne}}const le=(e,t)=>{const s=["","K","M","G","T","P","E","Z"];let i=t||0,o=e||0;return o>=1e3?(o/=1e3,i+=1,i>=s.length?"???":le(o,i)):0===i?`${o}${s[i]}`:`${o.toFixed(1)}${s[i]}`};class ce{constructor(e){this.allProfileData={},this.defaultEndpoint=process.env.METRICHOR||ee.url,e&&(this.allProfileData=i.merge({profiles:{}},e)),this.allProfileData.endpoint&&(this.defaultEndpoint=this.allProfileData.endpoint)}profile(e){return e?i.merge({endpoint:this.defaultEndpoint},i.merge({profiles:{}},this.allProfileData).profiles[e]):{}}profiles(){return Object.keys(this.allProfileData.profiles||{})}}class he{constructor(e){this.options=i.assign({agent_version:K.version,local:!1,url:Z,user_agent:"EPI2ME API",signing:!0},e),this.log=this.options.log,this.cachedResponses={}}async list(e){const t=e.match(/^[a-z_]+/i)[0];return K.get(e,this.options).then(e=>e[`${t}s`])}async read(e,t){return K.get(`${e}/${t}`,this.options)}async user(){return this.options.local?{accounts:[{id_user_account:"none",number:"NONE",name:"None"}]}:K.get("user",this.options)}async status(){return K.get("status",this.options)}async jwt(){return K.post("authenticate",{},i.merge({handler:e=>e.headers["x-epi2me-jwt"]?Promise.resolve(e.headers["x-epi2me-jwt"]):Promise.reject(new Error("failed to fetch JWT"))},this.options))}async instanceToken(e,t){return K.post("token",i.merge(t,{id_workflow_instance:e}),i.assign({},this.options,{legacy_form:!0}))}async installToken(e){return K.post("token/install",{id_workflow:e},i.assign({},this.options,{legacy_form:!0}))}async attributes(){return this.list("attribute")}async workflows(){return this.list("workflow")}async amiImages(){if(this.options.local)throw new Error("amiImages unsupported in local mode");return this.list("ami_image")}async amiImage(e,t){let s,i,o;if(e&&t instanceof Object?(s=e,i=t,o="update"):e instanceof Object&&!t?(i=e,o="create"):(o="read",s=e),this.options.local)throw new Error("ami_image unsupported in local mode");if("update"===o)return K.put("ami_image",s,i,this.options);if("create"===o)return K.post("ami_image",i,this.options);if(!s)throw new Error("no id_ami_image specified");return this.read("ami_image",s)}async workflow(e,t,s){let o,r,n,a;if(e&&t&&s instanceof Function?(o=e,r=t,n=s,a="update"):e&&t instanceof Object&&!(t instanceof Function)?(o=e,r=t,a="update"):e instanceof Object&&t instanceof Function?(r=e,n=t,a="create"):e instanceof Object&&!t?(r=e,a="create"):(a="read",o=e,n=t instanceof Function?t:null),"update"===a)try{const e=await K.put("workflow",o,r,this.options);return n?n(null,e):Promise.resolve(e)}catch(u){return n?n(u):Promise.reject(u)}if("create"===a)try{const e=await K.post("workflow",r,this.options);return n?n(null,e):Promise.resolve(e)}catch(u){return n?n(u):Promise.reject(u)}if(!o){const e=new Error("no workflow id specified");return n?n(e):Promise.reject(e)}const l={};try{const e=await this.read("workflow",o);if(e.error)throw new Error(e.error);i.merge(l,e)}catch(u){return this.log.error(`${o}: error fetching workflow ${String(u)}`),n?n(u):Promise.reject(u)}i.merge(l,{params:{}});try{const e=await K.get(`workflow/config/${o}`,this.options);if(e.error)throw new Error(e.error);i.merge(l,e)}catch(u){return this.log.error(`${o}: error fetching workflow config ${String(u)}`),n?n(u):Promise.reject(u)}const c=i.filter(l.params,{widget:"ajax_dropdown"}),h=[...c.map((e,t)=>{const s=c[t];return new Promise((e,t)=>{const i=s.values.source.replace("{{EPI2ME_HOST}}","").replace(/&?apikey=\{\{EPI2ME_API_KEY\}\}/,"");K.get(i,this.options).then(t=>{const i=t[s.values.data_root];return i&&(s.values=i.map(e=>({label:e[s.values.items.label_key],value:e[s.values.items.value_key]}))),e()}).catch(e=>(this.log.error(`failed to fetch ${i}`),t(e)))})})];try{return await Promise.all(h),n?n(null,l):Promise.resolve(l)}catch(u){return this.log.error(`${o}: error fetching config and parameters ${String(u)}`),n?n(u):Promise.reject(u)}}async startWorkflow(e){return K.post("workflow_instance",e,i.assign({},this.options,{legacy_form:!0}))}async stopWorkflow(e){return K.put("workflow_instance/stop",e,null,i.assign({},this.options,{legacy_form:!0}))}async workflowInstances(e){return e&&e.run_id?K.get(`workflow_instance/wi?show=all&columns[0][name]=run_id;columns[0][searchable]=true;columns[0][search][regex]=true;columns[0][search][value]=${e.run_id};`,this.options).then(e=>e.data.map(e=>({id_workflow_instance:e.id_ins,id_workflow:e.id_flo,run_id:e.run_id,description:e.desc,rev:e.rev}))):this.list("workflow_instance")}async workflowInstance(e){return this.read("workflow_instance",e)}async workflowConfig(e){return K.get(`workflow/config/${e}`,this.options)}async register(e,t){return K.put("reg",e,{description:t||`${r.userInfo().username}@${r.hostname()}`},i.assign({},this.options,{signing:!1}))}async datasets(e){let t=e;return t||(t={}),t.show||(t.show="mine"),this.list(`dataset?show=${t.show}`)}async dataset(e){return this.options.local?this.datasets().then(t=>t.find(t=>t.id_dataset===e)):this.read("dataset",e)}async fetchContent(e){const t=i.assign({},this.options,{skip_url_mangle:!0,headers:{"Content-Type":""}});let s;try{if(s=(await K.head(e,t)).headers.etag,s&&this.cachedResponses[e]&&this.cachedResponses[e].etag===s)return this.cachedResponses[e].response}catch(r){this.log.warn(`Failed to HEAD request ${e}: ${String(r)}`)}const o=await K.get(e,t);return s&&(this.cachedResponses[e]={etag:s,response:o}),o}}class ue{constructor(e,t){this.debounces={},this.debounceWindow=i.merge({debounceWindow:2e3},t).debounceWindow,this.log=i.merge({log:{debug:()=>{}}},t).log,e.jwt().then(e=>{this.socket=y(t.url,{transportOptions:{polling:{extraHeaders:{Cookie:`x-epi2me-jwt=${e}`}}}}),this.socket.on("connect",()=>{this.log.debug("socket ready")})}).catch(e=>{this.log.error("socket connection failed - JWT authentication error")})}debounce(e,t){const s=i.merge(e)._uuid;if(s){if(this.debounces[s])return;this.debounces[s]=1,setTimeout(()=>{delete this.debounces[s]},this.debounceWindow)}t&&t(e)}watch(e,t){if(!this.socket)return this.log.debug(`socket not ready. requeueing watch on ${e}`),void setTimeout(()=>{this.watch(e,t)},1e3);this.socket.on(e,e=>this.debounce(e,t))}emit(e,t){if(!this.socket)return this.log.debug(`socket not ready. requeueing emit on ${e}`),void setTimeout(()=>{this.emit(e,t)},1e3);this.log.debug(`socket emit ${e} ${JSON.stringify(t)}`),this.socket.emit(e,t)}}class pe{constructor(e){let t;if(t="string"===typeof e||"object"===typeof e&&e.constructor===String?JSON.parse(e):e||{},t.endpoint&&(t.url=t.endpoint,delete t.endpoint),t.log){if(!i.every([t.log.info,t.log.warn,t.log.error,t.log.debug,t.log.json],i.isFunction))throw new Error("expected log object to have error, debug, info, warn and json methods");this.log=t.log}else this.log={info:e=>{console.info(`[${(new Date).toISOString()}] INFO: ${e}`)},debug:e=>{console.debug(`[${(new Date).toISOString()}] DEBUG: ${e}`)},warn:e=>{console.warn(`[${(new Date).toISOString()}] WARN: ${e}`)},error:e=>{console.error(`[${(new Date).toISOString()}] ERROR: ${e}`)},json:e=>{console.log(JSON.stringify(e))}};this.stopped=!0,this.uploadState$=new u.BehaviorSubject(!1),this.analyseState$=new u.BehaviorSubject(!1),this.reportState$=new u.BehaviorSubject(!1),this.instanceTelemetry$=new u.BehaviorSubject(null),this.experimentalWorkerStatus$=new u.BehaviorSubject(null),this.runningStates$=u.combineLatest(this.uploadState$,this.analyseState$,this.reportState$),this.states={upload:{filesCount:0,success:{files:0,bytes:0,reads:0},types:{},niceTypes:"",progress:{bytes:0,total:0}},download:{progress:{},success:{files:0,reads:0,bytes:0},fail:0,types:{},niceTypes:""},warnings:[]},this.liveStates$=new u.BehaviorSubject(this.states),this.config={options:i.defaults(t,ee),instance:{id_workflow_instance:t.id_workflow_instance,inputQueueName:null,outputQueueName:null,outputQueueURL:null,discoverQueueCache:{},bucket:null,bucketFolder:null,remote_addr:null,chain:null,key_id:null}},this.config.instance.awssettings={region:this.config.options.region},this.REST=new he(i.merge({log:this.log},this.config.options)),this.graphQL=new ae(i.merge({log:this.log},this.config.options)),this.timers={downloadCheckInterval:null,stateCheckInterval:null,fileCheckInterval:null,transferTimeouts:{},visibilityIntervals:{},summaryTelemetryInterval:null}}async socket(){if(this.mySocket)return this.mySocket;this.mySocket=new ue(this.REST,i.merge({log:this.log},this.config.options));const{id_workflow_instance:e}=this.config.instance;return e&&this.mySocket.watch(`workflow_instance:state:${e}`,e=>{const{instance:t}=this.config;if(t){const{summaryTelemetry:s}=t,i=Object.entries(t.chain.components).sort((e,t)=>e[0]-t[0]).reduce((t,i)=>{const[o,r]=i;if(!e[o])return t;const n=+o,a=n&&Object.keys(s[r.wid])[0]||"ROOT",[l,c,h]=e[o].split(",").map(e=>Math.max(0,+e));return[...t,{running:l,complete:c,error:h,step:n,name:a}]},[]);this.experimentalWorkerStatus$.next(i)}}),this.mySocket}async realtimeFeedback(e,t){(await this.socket()).emit(e,t)}stopTimer(e){this.timers[e]&&(this.log.debug(`clearing ${e} interval`),clearInterval(this.timers[e]),this.timers[e]=null)}async stopAnalysis(){this.stopUpload(),this.stopped=!0;const{id_workflow_instance:e}=this.config.instance;if(e){try{this.config.options.graphQL?await this.graphQL.stopWorkflow({variables:{idWorkflowInstance:e}}):await this.REST.stopWorkflow(e),this.analyseState$.next(!1)}catch(t){return this.log.error(`Error stopping instance: ${String(t)}`),Promise.reject(t)}this.log.info(`workflow instance ${e} stopped`)}return Promise.resolve()}async stopUpload(){this.log.debug("stopping watchers"),["stateCheckInterval","fileCheckInterval"].forEach(e=>this.stopTimer(e)),this.uploadState$.next(!1)}async stopEverything(){this.stopAnalysis(),Object.keys(this.timers.transferTimeouts).forEach(e=>{this.log.debug(`clearing transferTimeout for ${e}`),clearTimeout(this.timers.transferTimeouts[e]),delete this.timers.transferTimeouts[e]}),Object.keys(this.timers.visibilityIntervals).forEach(e=>{this.log.debug(`clearing visibilityInterval for ${e}`),clearInterval(this.timers.visibilityIntervals[e]),delete this.timers.visibilityIntervals[e]}),this.downloadWorkerPool&&(this.log.debug("clearing downloadWorkerPool"),await Promise.all(Object.values(this.downloadWorkerPool)),this.downloadWorkerPool=null),["summaryTelemetryInterval","downloadCheckInterval"].forEach(e=>this.stopTimer(e))}reportProgress(){const{upload:e,download:t}=this.states;this.log.json({progress:{download:t,upload:e}})}storeState(e,t,s,i){const o=i||{};this.states[e]||(this.states[e]={}),this.states[e][t]||(this.states[e][t]={}),"incr"===s?Object.keys(o).forEach(s=>{this.states[e][t][s]=this.states[e][t][s]?this.states[e][t][s]+parseInt(o[s],10):parseInt(o[s],10)}):Object.keys(o).forEach(s=>{this.states[e][t][s]=this.states[e][t][s]?this.states[e][t][s]-parseInt(o[s],10):-parseInt(o[s],10)});try{this.states[e].success.niceReads=le(this.states[e].success.reads)}catch(n){this.states[e].success.niceReads=0}try{this.states[e].progress.niceSize=le(this.states[e].success.bytes+this.states[e].progress.bytes||0)}catch(n){this.states[e].progress.niceSize=0}try{this.states[e].success.niceSize=le(this.states[e].success.bytes)}catch(n){this.states[e].success.niceSize=0}this.states[e].niceTypes=Object.keys(this.states[e].types||{}).sort().map(t=>`${this.states[e].types[t]} ${t}`).join(", ");const r=Date.now();(!this.stateReportTime||r-this.stateReportTime>2e3)&&(this.stateReportTime=r,this.reportProgress()),this.liveStates$.next(Object.assign({},this.states))}uploadState(e,t,s){return this.storeState("upload",e,t,s)}downloadState(e,t,s){return this.storeState("download",e,t,s)}url(){return this.config.options.url}apikey(){return this.config.options.apikey}attr(e,t){if(!(e in this.config.options))throw new Error(`config object does not contain property ${e}`);return t?(this.config.options[e]=t,this):this.config.options[e]}stats(e){return this.states[e]}}pe.version=K.version,pe.Profile=ce,pe.REST=he,pe.utils=K;const de={fastq:function(e){return new Promise((t,i)=>{let o=1,r=-1,n={size:0};try{n=s.statSync(e)}catch(a){return void i(a)}s.createReadStream(e).on("data",e=>{r=-1,o-=1;do{r=e.indexOf(10,r+1),o+=1}while(-1!==r)}).on("end",()=>t({type:"fastq",bytes:n.size,reads:Math.floor(o/4)})).on("error",i)})},fasta:function(e){return new Promise((t,i)=>{let o=1,r=-1,n={size:0};try{n=s.statSync(e)}catch(a){i(a)}s.createReadStream(e).on("data",e=>{r=-1,o-=1;do{r=e.indexOf(62,r+1),o+=1}while(-1!==r)}).on("end",()=>t({type:"fasta",bytes:n.size,sequences:Math.floor((1+o)/2)})).on("error",i)})},fastqgz:function(e){return new Promise((t,i)=>{let o=1,r=-1,n={size:0};try{n=s.statSync(e)}catch(l){return void i(l)}const a=k.createGunzip();s.createReadStream(e).pipe(a).on("data",e=>{r=-1,o-=1;do{r=e.indexOf(10,r+1),o+=1}while(-1!==r)}).on("end",()=>t({type:"gz",bytes:n.size,reads:Math.floor(o/4)})).on("error",i)})},default:async function(e){return s.stat(e).then(e=>({type:"bytes",bytes:e.size}))}},ge={fq:"fastq",fa:"fasta"};function fe(e){if("string"!==typeof e&&!(e instanceof String))return Promise.resolve({});let t=n.extname(e).toLowerCase().replace(/^[.]/,"");if(ge[t]&&(t=ge[t]),"gz"===t){t=e.split(".").slice(1).reduce((e,t)=>e+(ge[t]||t),"")}return de[t]||(t="default"),de[t](e)}class me extends ce{constructor(e,t){super({}),this.raiseExceptions=!!t,this.prefsFile=e||me.profilePath(),this.allProfileData={};try{this.allProfileData=i.merge({profiles:{}},s.readJSONSync(this.prefsFile)),this.allProfileData.endpoint&&(this.defaultEndpoint=this.allProfileData.endpoint)}catch(o){if(this.raiseExceptions)throw o}}static profilePath(){return n.join(o.homedir(),".epi2me.json")}profile(e,t){if(e&&t){i.merge(this.allProfileData,{profiles:{[e]:t}});try{s.writeJSONSync(this.prefsFile,this.allProfileData)}catch(o){if(this.raiseExceptions)throw o}}if(e){if(!this.allProfileData.profiles)throw new Error("cannot read property");return i.merge({endpoint:this.defaultEndpoint},this.allProfileData.profiles[e])}return{}}}class we{static MakeQueryablePromise(e){if(e.isResolved)return e;let t=!0,s=!1,i=!1;const o=e.then(e=>(i=!0,t=!1,e)).catch(e=>{throw s=!0,t=!1,e});return o.dependsOn=e,o.isResolved=()=>i,o.isPending=()=>t,o.isRejected=()=>s,o}constructor(e){const t=i.merge({bandwidth:1,interval:500},e);this.bandwidth=t.bandwidth,this.interval=t.interval,this.pipeline=[],this.running=[],this.completed=0,this.intervalId=null,"start"in t&&!t.start||this.start()}enqueue(e){this.pipeline.push(e)}start(){this.intervalId||(this.intervalId=setInterval(()=>{this.monitorInterval()},this.interval))}stop(){clearInterval(this.intervalId),delete this.intervalId}state(){return{queued:this.pipeline.length,running:this.running.length,completed:this.completed,state:this.intervalId?"running":"stopped"}}monitorInterval(){this.running.map((e,t)=>e.isPending()?null:t).filter(e=>e).reverse().forEach(e=>{this.running.splice(e,1),this.completed+=1});const e=this.bandwidth-this.running.length;for(let t=0;t<e;t+=1){const e=this.pipeline.shift();if(!e)return;this.running.push(we.MakeQueryablePromise(e()))}}}class ye extends he{async workflows(e){if(!this.options.local)return super.workflows(e);const t=n.join(this.options.url,"workflows");let i;try{return i=(await s.readdir(t)).filter(e=>s.statSync(n.join(t,e)).isDirectory()).map(e=>n.join(t,e,"workflow.json")).map(e=>s.readJsonSync(e)),e?e(null,i):Promise.resolve(i)}catch(o){return this.log.warn(o),e?e(void 0):Promise.reject(void 0)}}async workflow(e,t,i){if(!this.options.local||!e||"object"===typeof e||i)return super.workflow(e,t,i);const o=n.join(this.options.url,"workflows"),r=n.join(o,e,"workflow.json");try{const e=await s.readJson(r);return i?i(null,e):Promise.resolve(e)}catch(a){return i?i(a):Promise.reject(a)}}async workflowInstances(e,t){if(!this.options.local)return super.workflowInstances(e,t);let i,o;if(!e||e instanceof Function||void 0!==t?(i=e,o=t):o=e,o){const e=new Error("querying of local instances unsupported in local mode");return i?i(e):Promise.reject(e)}const r=n.join(this.options.url,"instances");try{let e=await s.readdir(r);return e=e.filter(e=>s.statSync(n.join(r,e)).isDirectory()),e=e.map(e=>{const t=n.join(r,e,"workflow.json");let i;try{i=s.readJsonSync(t)}catch(o){i={id_workflow:"-",description:"-",rev:"0.0"}}return i.id_workflow_instance=e,i.filename=t,i}),i?i(null,e):Promise.resolve(e)}catch(a){return i?i(a):Promise.reject(a)}}async datasets(e,t){if(!this.options.local)return super.datasets(e,t);let i,o;if(!e||e instanceof Function||void 0!==t?(i=e,o=t):o=e,o||(o={}),o.show||(o.show="mine"),"mine"!==o.show)return i(new Error("querying of local datasets unsupported in local mode"));const r=n.join(this.options.url,"datasets");try{let e=await s.readdir(r);e=e.filter(e=>s.statSync(n.join(r,e)).isDirectory());let t=0;return e=e.sort().map(e=>(t+=1,{is_reference_dataset:!0,summary:null,dataset_status:{status_label:"Active",status_value:"active"},size:0,prefix:e,id_workflow_instance:null,id_account:null,is_consented_human:null,data_fields:null,component_id:null,uuid:e,is_shared:!1,id_dataset:t,id_user:null,last_modified:null,created:null,name:e,source:e,attributes:null})),i?i(null,e):Promise.resolve(e)}catch(a){return this.log.warn(a),i?i(null,[]):Promise.resolve([])}}async bundleWorkflow(e,t,s){return K.pipe(`workflow/bundle/${e}.tar.gz`,t,this.options,s)}}class ke{constructor(){this.experiments={}}async getExperiments({sourceDir:e=ee.sampleDirectory,refresh:t=!1}){return Object.keys(this.experiments).length&&!t||await this.updateExperiments(e),this.experiments}async updateExperiments(e=ee.sampleDirectory){const t=(new S).withBasePath().withErrors().filter(e=>e.includes("sequencing_summary")).exclude(e=>e.includes("fastq_")).withMaxDepth(3).crawl(e);let s;try{s=await t.withPromise()}catch(i){return}this.experiments=s.reduce((e,t)=>{var s;const[i,o]=t.split(n.sep).slice(-3),r=/(?<date>[0-9]{8})_(?<time>[0-9]{4})_.*_(?<flowcell>\w+\d+)_\w+/;if(!r.test(o))return e;const{date:a,time:l,flowcell:c}=null===(s=r.exec(o))||void 0===s?void 0:s.groups,h=`${a.slice(0,4)}-${a.slice(4,6)}-${a.slice(6,8)}`,u=`T${l.slice(0,2)}:${l.slice(2,4)}:00`,p=new Date(h+u);return e[i]={startDate:`${p.toDateString()} ${p.toLocaleTimeString()}`,samples:[...e[i]?e[i].samples:[],{sample:o,flowcell:c,path:`${n.dirname(t)}/fastq_pass`}]},e},{})}}class ve{constructor(e,t,s,o,r){if(this.id_workflow_instance=e,this.children=s,this.options=i.merge(o),this.log=this.options.log,this.REST=t,this.graphQL=r,!e)throw new Error("must specify id_workflow_instance");if(!s||!s.length)throw new Error("must specify children to session")}async session(){if(this.sts_expiration&&this.sts_expiration>Date.now())return Promise.resolve();this.log.debug("new instance token needed");try{const e=this.options.useGraphQL?(await this.graphQL.instanceToken({variables:{idWorkflowInstance:this.id_workflow_instance}})).data.token:await this.REST.instanceToken(this.id_workflow_instance,this.options);this.log.debug(`allocated new instance token expiring at ${e.expiration}`),this.sts_expiration=new Date(e.expiration).getTime()-60*parseInt(this.options.sessionGrace||"0",10);const t={};this.options.proxy&&i.merge(t,{httpOptions:{agent:b(this.options.proxy,!0)}}),i.merge(t,{region:this.options.region},e),this.children.forEach(e=>{try{e.config.update(t)}catch(s){this.log.warn(`failed to update config on ${String(e)}: ${String(s)}`)}})}catch(e){this.log.warn(`failed to fetch instance token: ${String(e)}`)}return Promise.resolve()}}async function Se(e,t,o,r,a,l){const{maxChunkBytes:c,maxChunkReads:h}=i.merge(t),u=n.dirname(e),p=n.basename(e),d=p.match(/^[^.]+/),g=d?d[0]:"",f=p.replace(g,""),m=n.join(u,g);if(!c&&!h)return o(e).then(()=>({source:e,split:!1,chunks:[e]}));const w=await s.stat(e);return c&&w.size<c?o(e).then(()=>({source:e,split:!1,chunks:[e]})):new Promise(t=>{let n,u,p=0,d=0,g="",w=0,y=0;const k={source:e,split:!0,chunks:[]};let v;const S=[new Promise(e=>{v=e})];$.createInterface({input:a(e)}).on("line",async e=>{d+=1,g+=e,g+="\n",d>=4&&(d=0,(async e=>{if(!w){p+=1,n=`${m}_${p}${f}`;const e=new Promise((e,t)=>{const i=n,a=()=>{o(i).then(()=>{e(i)}).catch(e=>{t(e)}).finally(()=>{s.unlink(i).catch(e=>{r.warn(`Error unlinking chunk ${i}: ${String(e)}`)})})};l?u=l(i,a):(u=s.createWriteStream(i),u.on("close",a))});S.push(e)}w+=1,y+=e.length,u.write(e,()=>{}),(c&&y>=c||h&&w>=h)&&(w=0,y=0,u.end())})(g),g="")}).on("close",()=>{u.end(),v(),Promise.all(S).then(e=>{e.shift(),t(i.merge({chunks:e},k))})}).on("error",t=>{r.error(`Error chunking ${e}: ${String(t)}`)})})}async function be(e,t,i,o){return Se(e,t,i,o,e=>s.createReadStream(e))}async function $e(e,t,i,o){return Se(e,t,i,o,e=>s.createReadStream(e).pipe(v.createGunzip()),(e,t)=>{const i=s.createWriteStream(e);i.on("close",t);const o=v.createGzip();return o.pipe(i),o})}const Ie=()=>{const e=process.env.APPDATA||("darwin"===process.platform?n.join(o.homedir(),"Library/Application Support"):o.homedir());return process.env.EPI2ME_HOME||n.join(e,"linux"===process.platform?".epi2me":"EPI2ME")};class _e extends pe{constructor(e){super(e),this.config.options.inputFolders=this.config.options.inputFolders||[],this.config.options.inputFolder&&this.config.options.inputFolders.push(this.config.options.inputFolder),this.REST=new ye(i.merge({},{log:this.log},this.config.options)),this.SampleReader=new ke,this.uploadsInProgress=[]}async sessionedS3(){return this.sessionManager||(this.sessionManager=this.initSessionManager()),await this.sessionManager.session(),new t.S3({useAccelerateEndpoint:"on"===this.config.options.awsAcceleration})}async sessionedSQS(){return this.sessionManager||(this.sessionManager=this.initSessionManager()),await this.sessionManager.session(),new t.SQS}async deleteMessage(e){try{const t=await this.discoverQueue(this.config.instance.outputQueueName);return(await this.sessionedSQS()).deleteMessage({QueueUrl:t,ReceiptHandle:e.ReceiptHandle}).promise()}catch(t){return this.log.error(`deleteMessage exception: ${String(t)}`),this.states.download.failure||(this.states.download.failure={}),this.states.download.failure[t]=this.states.download.failure[t]?this.states.download.failure[t]+1:1,Promise.reject(t)}}async discoverQueue(e){if(this.config.instance.discoverQueueCache[e])return Promise.resolve(this.config.instance.discoverQueueCache[e]);let t;this.log.debug(`discovering queue for ${e}`);try{const s=await this.sessionedSQS();t=await s.getQueueUrl({QueueName:e}).promise()}catch(s){return this.log.error(`Error: failed to find queue for ${e}: ${String(s)}`),Promise.reject(s)}return this.log.debug(`found queue ${t.QueueUrl}`),this.config.instance.discoverQueueCache[e]=t.QueueUrl,Promise.resolve(t.QueueUrl)}async queueLength(e){if(!e)return Promise.reject(new Error("no queueURL specified"));const t=e.match(/([\w\-_]+)$/)[0];this.log.debug(`querying queue length of ${t}`);try{const t=await this.sessionedSQS(),s=await t.getQueueAttributes({QueueUrl:e,AttributeNames:["ApproximateNumberOfMessages"]}).promise();if((null===s||void 0===s?void 0:s.Attributes)&&"ApproximateNumberOfMessages"in s.Attributes){let e=s.Attributes.ApproximateNumberOfMessages;return e=parseInt(e,10)||0,Promise.resolve(e)}return Promise.reject(new Error("unexpected response"))}catch(s){return this.log.error(`error in getQueueAttributes ${String(s)}`),Promise.reject(s)}}async autoStart(e,t){const s=await this.autoStartGeneric(e,()=>this.REST.startWorkflow(e),t);return this.setClassConfigREST(s),this.autoConfigure(s,t)}async autoStartGQL(e,t){const s=await this.autoStartGeneric(e,()=>this.graphQL.startWorkflow({variables:e}),t);return this.setClassConfigGQL(s),this.autoConfigure(this.config.instance,t)}async autoStartGeneric(e,t,s){let i;this.stopped=!1;try{i=await t(),this.analyseState$.next(!0)}catch(o){const e=`Failed to start workflow: ${String(o)}`;return this.log.warn(e),s?s(e):Promise.reject(o)}return this.config.workflow=JSON.parse(JSON.stringify(e)),this.log.info(`instance ${JSON.stringify(i)}`),this.log.info(`workflow config ${JSON.stringify(this.config.workflow)}`),i}async autoJoin(e,t){let s;this.stopped=!1,this.config.instance.id_workflow_instance=e;try{s=await this.REST.workflowInstance(e)}catch(i){const e=`Failed to join workflow instance: ${String(i)}`;return this.log.warn(e),t?t(e):Promise.reject(i)}return"stopped"===s.state?(this.log.warn(`workflow ${e} is already stopped`),t?t("could not join workflow"):Promise.reject(new Error("could not join workflow"))):(this.config.workflow=this.config.workflow||{},this.log.debug(`instance ${JSON.stringify(s)}`),this.log.debug(`workflow config ${JSON.stringify(this.config.workflow)}`),this.setClassConfigREST(s),this.autoConfigure(s,t))}setClassConfigGQL({data:{startData:{bucket:e,idUser:t,remoteAddr:s,userDefined:i={},instance:{outputqueue:o,keyId:r,startDate:n,idWorkflowInstance:a,mappedTelemetry:l,chain:c,workflowImage:{region:{name:h},workflow:{idWorkflow:u},inputqueue:p}}}}}){const d={bucket:e,user_defined:i,id_user:parseInt(t),remote_addr:s,id_workflow_instance:a,key_id:r,start_date:n,outputQueueName:o,summaryTelemetry:l,inputQueueName:p,id_workflow:parseInt(u),region:h||this.config.options.region,bucketFolder:`${o}/${t}/${a}`,chain:K.convertResponseToObject(c)};this.config.instance=Object.assign(Object.assign({},this.config.instance),d)}setClassConfigREST(e){["id_workflow_instance","id_workflow","remote_addr","key_id","bucket","user_defined","start_date","id_user"].forEach(t=>{this.config.instance[t]=e[t]}),this.config.instance.inputQueueName=e.inputqueue,this.config.instance.outputQueueName=e.outputqueue,this.config.instance.region=e.region||this.config.options.region,this.config.instance.bucketFolder=`${e.outputqueue}/${e.id_user}/${e.id_workflow_instance}`,this.config.instance.summaryTelemetry=e.telemetry,e.chain&&(this.config.instance.chain=K.convertResponseToObject(e.chain))}initSessionManager(e,s){return new ve(this.config.instance.id_workflow_instance,this.REST,[t,...s||[]],i.merge({sessionGrace:this.config.options.sessionGrace,proxy:this.config.options.proxy,region:this.config.instance.region,log:this.log,useGraphQL:this.config.options.useGraphQL},e),this.graphQL)}async autoConfigure(e,t){if(!this.config.options.inputFolders.length)throw new Error("must set inputFolder");if(!this.config.options.outputFolder)throw new Error("must set outputFolder");if(!this.config.instance.bucketFolder)throw new Error("bucketFolder must be set");if(!this.config.instance.inputQueueName)throw new Error("inputQueueName must be set");if(!this.config.instance.outputQueueName)throw new Error("outputQueueName must be set");s.mkdirpSync(this.config.options.outputFolder);const i=n.join(Ie(),"instances"),o=n.join(i,this.config.instance.id_workflow_instance);this.db=new Y(o,{idWorkflowInstance:this.config.instance.id_workflow_instance,inputFolders:this.config.options.inputFolders},this.log);const r=this.config.instance.id_workflow_instance?`telemetry-${this.config.instance.id_workflow_instance}.log`:"telemetry.log",a=n.join(this.config.options.outputFolder,"epi2me-logs"),l=n.join(a,r);return s.mkdirp(a,e=>{if(e&&!String(e).match(/EEXIST/))this.log.error(`error opening telemetry log stream: mkdirpException:${String(e)}`);else try{this.telemetryLogStream=s.createWriteStream(l,{flags:"a"}),this.log.info(`logging telemetry to ${l}`)}catch(t){this.log.error(`error opening telemetry log stream: ${String(t)}`)}}),t&&t(null,this.config.instance),this.timers.summaryTelemetryInterval=setInterval(()=>{this.stopped?clearInterval(this.timers.summaryTelemetryInterval):this.fetchTelemetry()},1e4*this.config.options.downloadCheckInterval),this.timers.downloadCheckInterval=setInterval(()=>{this.stopped?clearInterval(this.timers.downloadCheckInterval):this.checkForDownloads()},1e3*this.config.options.downloadCheckInterval),this.timers.stateCheckInterval=setInterval(async()=>{if(this.stopped)clearInterval(this.timers.stateCheckInterval);else try{let t;if(this.config.options.useGraphQL?({data:{instanceObj:t}}=await this.graphQL.query("query workflowInstance($idWorkflowInstance: ID!) {\n              instanceObj:workflowInstance(idWorkflowInstance: $idWorkflowInstance) {\n                stop_date: stopDate\n                state\n              }\n            }")({variables:{idWorkflowInstance:this.config.instance.id_workflow_instance}})):t=await this.REST.workflowInstance(this.config.instance.id_workflow_instance),"stopped"===t.state){this.log.warn(`instance was stopped remotely at ${t.stop_date}. shutting down the workflow.`);try{const e=await this.stopEverything();"function"===typeof e.config.options.remoteShutdownCb&&e.config.options.remoteShutdownCb(`instance was stopped remotely at ${t.stop_date}`)}catch(e){this.log.error(`Error whilst stopping: ${String(e)}`)}}}catch(t){this.log.warn(`failed to check instance state: ${(null===t||void 0===t?void 0:t.error)?t.error:t}`)}},1e3*this.config.options.stateCheckInterval),this.sessionManager=this.initSessionManager(),await this.sessionManager.session(),this.reportProgress(),this.loadUploadFiles(),this.uploadState$.next(!0),this.timers.fileCheckInterval=setInterval(this.loadUploadFiles.bind(this),1e3*this.config.options.fileCheckInterval),Promise.resolve(e)}async stopUpload(){for(const e of this.uploadsInProgress)e.abort();if(this.uploadsInProgress=[],await super.stopUpload(),this.log.debug("clearing split files"),this.db)return this.db.splitClean()}async stopEverything(){delete this.sessionManager,await super.stopEverything()}async checkForDownloads(){if(this.checkForDownloadsRunning)return Promise.resolve();this.checkForDownloadsRunning=!0,this.log.debug("checkForDownloads checking for downloads");try{const e=await this.discoverQueue(this.config.instance.outputQueueName),t=await this.queueLength(e);t?(this.log.debug(`downloads available: ${t}`),await this.downloadAvailable()):this.log.debug("no downloads available")}catch(e){this.log.warn(`checkForDownloads error ${String(e)}`),this.states.download.failure||(this.states.download.failure={}),this.states.download.failure[e]=this.states.download.failure[e]?this.states.download.failure[e]+1:1}return this.checkForDownloadsRunning=!1,Promise.resolve()}async downloadAvailable(){const e=Object.keys(this.downloadWorkerPool||{}).length;if(e>=this.config.options.transferPoolSize)return this.log.debug(`${e} downloads already queued`),Promise.resolve();let t;try{const s=await this.discoverQueue(this.config.instance.outputQueueName);this.log.debug("fetching messages");const i=await this.sessionedSQS();t=await i.receiveMessage({AttributeNames:["All"],QueueUrl:s,VisibilityTimeout:this.config.options.inFlightDelay,MaxNumberOfMessages:this.config.options.transferPoolSize-e,WaitTimeSeconds:this.config.options.waitTimeSeconds}).promise()}catch(s){return this.log.error(`receiveMessage exception: ${String(s)}`),this.states.download.failure[s]=this.states.download.failure[s]?this.states.download.failure[s]+1:1,Promise.reject(s)}return this.receiveMessages(t)}async loadUploadFiles(){if(this.dirScanInProgress)return Promise.resolve();this.dirScanInProgress=!0,this.log.debug("upload: started directory scan");try{const e=e=>this.db.seenUpload(e),t=await K.loadInputFiles(this.config.options,this.log,e);let s=0;const i=()=>new Promise(e=>{if(this.stopped)return t.length=0,this.log.debug("upload: skipping, stopped"),void e();if(s>this.config.options.transferPoolSize)return void setTimeout(e,1e3);const i=t.splice(0,this.config.options.transferPoolSize-s);s+=i.length,this.enqueueUploadFiles(i).then().catch(e=>{this.log.error(`upload: exception in enqueueUploadFiles: ${String(e)}`)}).finally(()=>{s-=i.length,e()})});for(;t.length;)await i()}catch(e){this.log.error(`upload: exception in loadInputFiles: ${String(e)}`)}return this.dirScanInProgress=!1,this.log.debug("upload: finished directory scan"),Promise.resolve()}async enqueueUploadFiles(e){let t=0,s=0,o=0,r=0,a={};if(!i.isArray(e)||!e.length)return Promise.resolve();if(this.log.info(`enqueueUploadFiles ${e.length} files: ${e.map(e=>e.path).join(" ")}.`),"workflow"in this.config)if("workflow_attributes"in this.config.workflow)a=this.config.workflow.workflow_attributes;else if("attributes"in this.config.workflow){let{attributes:e}=this.config.workflow;if(e||(e={}),["max_size","max_files","split_size","split_reads"].forEach(t=>{`epi2me:${t}`in e&&(a[t]=parseInt(e[`epi2me:${t}`],10))}),"epi2me:category"in e){e["epi2me:category"].includes("storage")&&(a.requires_storage=!0)}}if(this.log.info(`enqueueUploadFiles settings ${JSON.stringify(a)}`),"requires_storage"in a&&a.requires_storage&&!("storage_account"in this.config.workflow)){const e={msg:"ERROR: Workflow requires storage enabled. Please provide a valid storage account [ --storage ].",type:"WARNING_STORAGE_ENABLED"};return this.log.error(e.msg),this.states.warnings.push(e),Promise.resolve()}if("split_size"in a&&(o=parseInt(a.split_size,10),this.log.info(`enqueueUploadFiles splitting supported files at ${o} bytes`)),"split_reads"in a&&(r=parseInt(a.split_reads,10),this.log.info(`enqueueUploadFiles splitting supported files at ${r} reads`)),"max_size"in a&&(s=parseInt(a.max_size,10),this.log.info(`enqueueUploadFiles restricting file size to ${s}`)),"max_files"in a&&(t=parseInt(a.max_files,10),this.log.info(`enqueueUploadFiles restricting file count to ${t}`),e.length>t)){const s={msg:`ERROR: ${e.length} files found. Workflow can only accept ${t}. Please move the extra files away.`,type:"WARNING_FILE_TOO_MANY"};return this.log.error(s.msg),this.states.warnings.push(s),Promise.resolve()}this.states.upload.filesCount+=e.length;const l=e.map(async e=>{var i;const a=e;if(t&&this.states.upload.filesCount>t){const e=`Maximum ${t} file(s) already uploaded. Marking ${a.relative} as skipped.`,s={msg:e,type:"WARNING_FILE_TOO_MANY"};this.log.error(e),this.states.warnings.push(s),this.states.upload.filesCount-=1,a.skip="SKIP_TOO_MANY"}else if(0===a.size){const e=`The file "${a.relative}" is empty. It will be skipped.`,t={msg:e,type:"WARNING_FILE_EMPTY"};a.skip="SKIP_EMPTY",this.states.upload.filesCount-=1,this.log.error(e),this.states.warnings.push(t)}else{if((null===(i=a.path)||void 0===i?void 0:i.match(/\.(?:fastq|fq)(?:\.gz)?$/))&&(o&&a.size>o||r)){const e=`${a.relative}${a.size>o?" is too big and":""} is going to be split`;this.log.warn(e);const t={msg:e,type:"WARNING_FILE_SPLIT"};this.states.warnings.push(t);const s=o?{maxChunkBytes:o}:{maxChunkReads:r},i=a.path.match(/\.gz$/)?$e:be,c=K.getFileID(),h=new we({bandwidth:this.config.options.transferPoolSize});let u=0;const p=async e=>(this.log.debug(`chunkHandler for ${e}`),await this.db.splitFile(e,a.path),this.stopped?(h.stop(),this.log.info(`stopped, so skipping ${e}`),Promise.reject(new Error("stopped"))):(u+=1,fe(e).then(t=>({name:n.basename(e),path:e,relative:e.replace(this.config.options.inputFolder,""),id:`${c}_${u}`,stats:t,size:t.bytes})).then(async e=>{const t=new Promise(t=>{h.enqueue(()=>(this.log.info(`chunk upload starting ${e.id} ${e.path}`),this.stopped?(this.log.info(`chunk upload skipped (stopped) ${e.id} ${e.path}`),h.stop(),t(),Promise.resolve()):this.uploadJob(e).then(()=>this.db.splitDone(e.path)).catch(t=>{this.log.error(`chunk upload failed ${e.id} ${e.path}: ${String(t)}`)}).finally(t)))});await t})));try{await i(a.path,s,p,this.log),h.stop()}catch(l){if(h.stop(),"Error: stopped"===String(l))return Promise.resolve();throw l}return this.db.uploadFile(a.path)}if(s&&a.size>s){const e=`The file "${a.relative}" is bigger than the maximum size limit (${le(s)}B). It will be skipped.`,t={msg:e,type:"WARNING_FILE_TOO_BIG"};a.skip="SKIP_TOO_BIG",this.states.upload.filesCount-=1,this.log.error(e),this.states.warnings.push(t)}else try{a.stats=await fe(a.path)}catch(c){this.log.error(`failed to stat ${a.path}: ${String(c)}`)}}return this.uploadJob(a)});try{return await Promise.all(l),this.log.info(`upload: inputBatchQueue (${l.length} jobs) complete`),this.loadUploadFiles()}catch(c){return this.log.error(`upload: enqueueUploadFiles exception ${String(c)}`),Promise.reject(c)}}async uploadJob(e){if("skip"in e)return this.db.skipFile(e.path);let t,s;try{this.log.info(`upload: ${e.id} starting`),t=await this.uploadHandler(e),this.log.info(`upload: ${t.id} uploaded and notified`)}catch(o){s=o,this.log.error(`upload: ${e.id} done, but failed: ${String(s)}`)}if(t||(t={}),s){if(this.log.error(`uploadJob ${s}`),this.states.upload.failure||(this.states.upload.failure={}),this.states.upload.failure[s]=this.states.upload.failure[s]?this.states.upload.failure[s]+1:1,String(s).match(/AWS.SimpleQueueService.NonExistentQueue/))return this.log.error("instance stopped because of a fatal error"),this.stopEverything()}else if(this.uploadState("success","incr",i.merge({files:1},t.stats)),t.name){const e=n.extname(t.name);this.uploadState("types","incr",{[e]:1})}return Promise.resolve()}async receiveMessages(e){return e&&e.Messages&&e.Messages.length?(this.downloadWorkerPool||(this.downloadWorkerPool={}),e.Messages.forEach(e=>{this.downloadWorkerPool[e.MessageId]=1;const t=setTimeout(()=>{throw this.log.error(`this.downloadWorkerPool timeoutHandle. Clearing queue slot for message: ${e.MessageId}`),new Error("download timed out")},1e3*(60+this.config.options.downloadTimeout));this.processMessage(e).catch(e=>{this.log.error(`processMessage ${String(e)}`)}).finally(()=>{clearTimeout(t),e&&delete this.downloadWorkerPool[e.MessageId]})}),this.log.info(`downloader queued ${e.Messages.length} messages for processing`),Promise.resolve()):(this.log.info("complete (empty)"),Promise.resolve())}async processMessage(e){var t,r,a,l,c,h,u;let p,d;if(!e)return this.log.debug("download.processMessage: empty message"),Promise.resolve();"Attributes"in e&&"ApproximateReceiveCount"in e.Attributes&&this.log.debug(`download.processMessage: ${e.MessageId} / ${e.Attributes.ApproximateReceiveCount}`);try{p=JSON.parse(e.Body)}catch(w){this.log.error(`error parsing JSON message.Body from message: ${JSON.stringify(e)} ${String(w)}`);try{await this.deleteMessage(e)}catch(y){this.log.error(`Exception deleting message: ${String(y)}`)}return Promise.resolve()}if(p.telemetry){const{telemetry:t}=p;if(t.tm_path)try{this.log.debug(`download.processMessage: ${e.MessageId} fetching telemetry`);const s=await this.sessionedS3(),i=await s.getObject({Bucket:p.bucket,Key:t.tm_path}).promise();this.log.info(`download.processMessage: ${e.MessageId} fetched telemetry`),t.batch=i.Body.toString("utf-8").split("\n").filter(e=>(null===e||void 0===e?void 0:e.length)>0).map(e=>{try{return JSON.parse(e)}catch(y){return this.log.error(`Telemetry Batch JSON Parse error: ${String(y)}`),e}})}catch(k){this.log.error(`Could not fetch telemetry JSON: ${String(k)}`)}try{this.telemetryLogStream.write(JSON.stringify(t)+o.EOL)}catch(v){this.log.error(`error writing telemetry: ${v}`)}this.config.options.telemetryCb&&this.config.options.telemetryCb(t)}if(!p.path)return this.log.warn("nothing to download"),Promise.resolve();const g=p.path.match(/[\w\W]*\/([\w\W]*?)$/),f=g?g[1]:"";if(d=n.join(this.config.options.outputFolder,this.config.instance.id_workflow_instance||""),null===(r=null===(t=p.telemetry)||void 0===t?void 0:t.hints)||void 0===r?void 0:r.folder){this.log.debug(`using folder hint ${p.telemetry.hints.folder}`);const e=p.telemetry.hints.folder.split("/").map(e=>e.toUpperCase());d=n.join.apply(null,[d,...e])}s.mkdirpSync(d);const m=n.join(d,f);if("data+telemetry"===this.config.options.downloadMode){const t=[""];let s=(null===(c=null===(l=null===(a=this.config)||void 0===a?void 0:a.workflow)||void 0===l?void 0:l.settings)||void 0===c?void 0:c.output_format)?this.config.workflow.settings.output_format:[];("string"===typeof s||s instanceof String)&&(s=s.trim().split(/[\s,]+/));try{t.push(...s)}catch(y){this.log.error(`Failed to work out workflow file suffixes: ${String(y)}`)}try{const s=t.map(t=>{const s=p.path+t,i=m+t;return this.log.debug(`download.processMessage: ${e.MessageId} downloading ${s} to ${i}`),new Promise((o,r)=>{this.initiateDownloadStream({bucket:p.bucket,path:s},e,i).then(o).catch(e=>{this.log.error(`Caught exception waiting for initiateDownloadStream: ${String(e)}`),t?r(e):o()})})});await Promise.all(s)}catch(y){this.log.error(`Exception fetching file batch: ${String(y)}`)}try{const e=!(null===(h=p.telemetry)||void 0===h||!h.json)&&p.telemetry.json.exit_status;e&&this.config.options.dataCb&&this.config.options.dataCb(m,e)}catch(k){this.log.warn(`failed to fire data callback: ${k}`)}}else{const e=(null===(u=p.telemetry.batch_summary)||void 0===u?void 0:u.reads_num)?p.telemetry.batch_summary.reads_num:1;this.downloadState("success","incr",{files:1,reads:e})}try{await this.deleteMessage(e)}catch(y){this.log.error(`Exception deleting message: ${String(y)}`)}return this.realtimeFeedback("workflow_instance:state",{type:"stop",id_workflow_instance:this.config.instance.id_workflow_instance,id_workflow:this.config.instance.id_workflow,component_id:"0",message_id:i.merge(e).MessageId,id_user:this.config.instance.id_user}).catch(e=>{this.log.warn(`realtimeFeedback failed: ${String(e)}`)}),Promise.resolve()}async initiateDownloadStream(e,t,o){return new Promise(async(r,a)=>{let l,c,h;try{l=await this.sessionedS3()}catch(d){a(d)}const u=t=>{if(this.log.error(`Error during stream of bucket=${e.bucket} path=${e.path} to file=${o} ${String(t)}`),clearTimeout(this.timers.transferTimeouts[o]),delete this.timers.transferTimeouts[o],!c.networkStreamError)try{c.networkStreamError=1,c.close(),s.remove(o).then(()=>{this.log.warn(`removed failed download ${o}`)}).catch(e=>{this.log.warn(`failed to remove ${o}. unlinkException: ${String(e)}`)}),h.destroy&&(this.log.error(`destroying read stream for ${o}`),h.destroy())}catch(d){this.log.error(`error handling stream error: ${String(d)}`)}};try{const t={Bucket:e.bucket,Key:e.path};c=s.createWriteStream(o);const i=l.getObject(t);i.on("httpHeaders",(e,t)=>{this.downloadState("progress","incr",{total:parseInt(t["content-length"],10)})}),h=i.createReadStream()}catch(g){return this.log.error(`getObject/createReadStream exception: ${String(g)}`),void a(g)}h.on("error",u),c.on("finish",async()=>{if(!c.networkStreamError){this.log.debug(`downloaded ${o}`);try{const e=n.extname(o),t=await fe(o);this.downloadState("success","incr",i.merge({files:1},t)),this.downloadState("types","incr",{[e]:1}),this.downloadState("progress","decr",{total:t.bytes,bytes:t.bytes})}catch(e){this.log.warn(`failed to stat ${o}: ${String(e)}`)}this.reportProgress()}}),c.on("close",s=>{this.log.debug(`closing writeStream ${o}`),s&&this.log.error(`error closing write stream ${s}`),clearInterval(this.timers.visibilityIntervals[o]),delete this.timers.visibilityIntervals[o],clearTimeout(this.timers.transferTimeouts[o]),delete this.timers.transferTimeouts[o],setTimeout(this.checkForDownloads.bind(this)),this.log.info(`download.initiateDownloadStream: ${t.MessageId} downloaded ${e.path} to ${o}`),r()}),c.on("error",u);const p=()=>{u(new Error("transfer timed out"))};this.timers.transferTimeouts[o]=setTimeout(p,1e3*this.config.options.downloadTimeout);this.timers.visibilityIntervals[o]=setInterval(async()=>{this.stopped&&(clearInterval(this.timers.visibilityIntervals[o]),delete this.timers.visibilityIntervals[o]);const e=this.config.instance.outputQueueURL,s=t.ReceiptHandle;this.log.debug({message_id:t.MessageId},"updateVisibility");try{await this.sqs.changeMessageVisibility({QueueUrl:e,ReceiptHandle:s,VisibilityTimeout:this.config.options.inFlightDelay}).promise()}catch(i){this.log.error({message_id:t.MessageId,queue:e,error:i},"Error setting visibility"),clearInterval(this.timers.visibilityIntervals[o])}},900*this.config.options.inFlightDelay),h.on("data",e=>{clearTimeout(this.timers.transferTimeouts[o]),this.timers.transferTimeouts[o]=setTimeout(p,1e3*this.config.options.downloadTimeout),this.downloadState("progress","incr",{bytes:e.length})}).pipe(c)})}async uploadHandler(e){const t=await this.sessionedS3();let i;const o=e.relative.replace(/^[\\/]+/,"").replace(/\\/g,"/").replace(/\//g,"_"),r=[this.config.instance.bucketFolder,"component-0",o,o].join("/").replace(/\/+/g,"/");let n;return new Promise((o,a)=>{const l=()=>{i&&!i.closed&&i.close(),a(new Error(`${e.name} timed out`))};n=setTimeout(l,1e3*(this.config.options.uploadTimeout+5));try{i=s.createReadStream(e.path)}catch(c){return clearTimeout(n),void a(c)}i.on("error",e=>{i.close();let t="error in upload readstream";(null===e||void 0===e?void 0:e.message)&&(t+=`: ${e.message}`),clearTimeout(n),a(new Error(t))}),i.on("open",()=>{const s={Bucket:this.config.instance.bucket,Key:r,Body:i};this.config.instance.key_id&&(s.SSEKMSKeyId=this.config.instance.key_id,s.ServerSideEncryption="aws:kms"),e.size&&(s["Content-Length"]=e.size),this.uploadState("progress","incr",{total:e.size});let c=0;const h=t.upload(s,{partSize:10485760,queueSize:1});this.uploadsInProgress.push(h);const u=this.initSessionManager(null,[h.service]);u.sts_expiration=this.sessionManager.sts_expiration,h.on("httpUploadProgress",async e=>{this.uploadState("progress","incr",{bytes:e.loaded-c}),c=e.loaded,clearTimeout(n),n=setTimeout(l,1e3*(this.config.options.uploadTimeout+5));try{await u.session()}catch(t){this.log.warn(`Error refreshing token: ${String(t)}`)}}),h.promise().then(()=>{this.log.info(`${e.id} S3 upload complete`),i.close(),clearTimeout(n),this.uploadComplete(r,e).then(()=>{o(e)}).catch(e=>{console.log("catch"),a(e)}).finally(()=>{this.uploadState("progress","decr",{total:e.size,bytes:e.size}),this.uploadsInProgress=this.uploadsInProgress.filter(e=>e!==h)})}).catch(t=>{this.log.warn(`${e.id} uploadStreamError ${t}`),a(t)})})})}async uploadComplete(e,t){this.log.info(`${t.id} uploaded to S3: ${e}`);const s={bucket:this.config.instance.bucket,outputQueue:this.config.instance.outputQueueName,remote_addr:this.config.instance.remote_addr,user_defined:this.config.instance.user_defined||null,apikey:this.config.options.apikey,id_workflow_instance:this.config.instance.id_workflow_instance,id_master:this.config.instance.id_workflow,utc:(new Date).toISOString(),path:e,prefix:e.substring(0,e.lastIndexOf("/"))};if(this.config.instance.chain)try{s.components=JSON.parse(JSON.stringify(this.config.instance.chain.components)),s.targetComponentId=this.config.instance.chain.targetComponentId}catch(r){return this.log.error(`${t.id} exception parsing components JSON ${String(r)}`),Promise.reject(r)}if(this.config.instance.key_id&&(s.key_id=this.config.instance.key_id),this.config.options.agent_address)try{s.agent_address=JSON.parse(this.config.options.agent_address)}catch(n){this.log.error(`${t.id} Could not parse agent_address ${String(n)}`)}s.components&&Object.keys(s.components).forEach(e=>{"uploadMessageQueue"===s.components[e].inputQueueName&&(s.components[e].inputQueueName=this.uploadMessageQueue),"downloadMessageQueue"===s.components[e].inputQueueName&&(s.components[e].inputQueueName=this.downloadMessageQueue)});let o={};try{const e=await this.discoverQueue(this.config.instance.inputQueueName),i=await this.sessionedSQS();this.log.info(`${t.id} sending SQS message to input queue`),o=await i.sendMessage({QueueUrl:e,MessageBody:JSON.stringify(s)}).promise()}catch(a){return this.log.error(`${t.id} exception sending SQS message: ${String(a)}`),Promise.reject(a)}return this.realtimeFeedback("workflow_instance:state",{type:"start",id_workflow_instance:this.config.instance.id_workflow_instance,id_workflow:this.config.instance.id_workflow,component_id:"0",message_id:i.merge(o).MessageId,id_user:this.config.instance.id_user}).catch(e=>{this.log.warn(`realtimeFeedback failed: ${String(e)}`)}),this.log.info(`${t.id} SQS message sent. Mark as uploaded`),this.db.uploadFile(t.path)}async fetchTelemetry(){var e,t;if(!(null===(t=null===(e=this.config)||void 0===e?void 0:e.instance)||void 0===t?void 0:t.summaryTelemetry))return Promise.resolve();const i=n.join(Ie(),"instances"),o=n.join(i,this.config.instance.id_workflow_instance),r=[];Object.keys(this.config.instance.summaryTelemetry).forEach(e=>{const t=this.config.instance.summaryTelemetry[e]||{};let i=t[Object.keys(t)[0]];if(!i)return;i.startsWith("http")||(i=R(this.config.options.url,i));const a=n.join(o,`${e}.json`);r.push(this.REST.fetchContent(i).then(e=>(s.writeJSONSync(a,e),this.reportState$.next(!0),this.log.debug(`fetched telemetry summary ${a}`),Promise.resolve(e))).catch(e=>(this.log.debug(`Error fetching telemetry: ${String(e)}`),Promise.resolve(null))))});let a=0;try{const e=await Promise.all(r);this.instanceTelemetry$.next(e)}catch(l){a+=1}return a&&this.log.warn("summary telemetry incomplete"),Promise.resolve()}}_e.version=K.version,_e.REST=ye,_e.utils=K,_e.SessionManager=ve,_e.EPI2ME_HOME=Ie(),_e.Profile=me,_e.Factory=class{constructor(e,t){this.EPI2ME=e,this.options=t,this.masterInstance=new e(this.options),this.log=this.masterInstance.log,this.REST=this.masterInstance.REST,this.graphQL=this.masterInstance.graphQL,this.SampleReader=this.masterInstance.SampleReader,this.utils=e.utils,this.version=e.version,this.runningInstances={}}async startRun(e,t){const s=new this.EPI2ME(Object.assign(Object.assign({},this.options),e));try{const e=await s.autoStart(t);this.runningInstances[e.id_workflow_instance]=s}catch(i){this.log.error(`Experienced error starting ${String(i)}`);try{await s.stopEverything()}catch(o){this.log.error(`Also experienced error stopping ${String(o)}`)}}return s}async startGQLRun(e,t){const s=new this.EPI2ME(Object.assign(Object.assign(Object.assign({},this.options),e),{useGraphQL:!0}));try{const e=await s.autoStartGQL(t);this.runningInstances[e.id_workflow_instance]=s,console.log(e)}catch(i){this.log.error(`Experienced error starting ${String(i)}`);try{await s.stopEverything()}catch(o){this.log.error(`Also experienced error stopping ${String(o)}`)}}return s}},module.exports=_e;
