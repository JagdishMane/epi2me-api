/**
 * Copyright Metrichor Ltd. (An Oxford Nanopore Technologies Company) 2020
 */

import e from"aws-sdk";import t from"fs-extra";import{merge as s,flatten as i,remove as o,assign as r,filter as n,every as a,isFunction as l,defaults as c,takeRight as h,isArray as u}from"lodash";import p,{homedir as d,EOL as f}from"os";import g from"path";import m from"sqlite";import w from"axios";import y from"crypto";import{httpsOverHttps as k,httpsOverHttp as v}from"tunnel";import{BehaviorSubject as S,combineLatest as $}from"rxjs";import b from"graphql-tag";import{InMemoryCache as I}from"apollo-cache-inmemory";import _ from"apollo-client";import{ApolloLink as E,execute as P}from"apollo-link";import{createHttpLink as T}from"apollo-link-http";import{buildAxiosFetch as j}from"@lifeomic/axios-fetch";import x from"socket.io-client";import O,{createGunzip as R}from"zlib";import N from"fdir";import C from"proxy-agent";import A from"readline";var M="undefined"!==typeof globalThis?globalThis:"undefined"!==typeof window?window:"undefined"!==typeof global?global:"undefined"!==typeof self?self:{};function F(e,t,s){return e(s={path:t,exports:{},require:function(e,t){return function(){throw new Error("Dynamic requires are not currently supported by @rollup/plugin-commonjs")}((void 0===t||null===t)&&s.path)}},s.exports),s.exports}var q=F((function(e,t){!function(s){var i=t&&!t.nodeType&&t,o=e&&!e.nodeType&&e,r="object"==typeof M&&M;r.global!==r&&r.window!==r&&r.self!==r||(s=r);var n,a,l=2147483647,c=/^xn--/,h=/[^\x20-\x7E]/,u=/[\x2E\u3002\uFF0E\uFF61]/g,p={overflow:"Overflow: input needs wider integers to process","not-basic":"Illegal input >= 0x80 (not a basic code point)","invalid-input":"Invalid input"},d=Math.floor,f=String.fromCharCode;function g(e){throw RangeError(p[e])}function m(e,t){for(var s=e.length,i=[];s--;)i[s]=t(e[s]);return i}function w(e,t){var s=e.split("@"),i="";return s.length>1&&(i=s[0]+"@",e=s[1]),i+m((e=e.replace(u,".")).split("."),t).join(".")}function y(e){for(var t,s,i=[],o=0,r=e.length;o<r;)(t=e.charCodeAt(o++))>=55296&&t<=56319&&o<r?56320==(64512&(s=e.charCodeAt(o++)))?i.push(((1023&t)<<10)+(1023&s)+65536):(i.push(t),o--):i.push(t);return i}function k(e){return m(e,(function(e){var t="";return e>65535&&(t+=f((e-=65536)>>>10&1023|55296),e=56320|1023&e),t+=f(e)})).join("")}function v(e,t){return e+22+75*(e<26)-((0!=t)<<5)}function S(e,t,s){var i=0;for(e=s?d(e/700):e>>1,e+=d(e/t);e>455;i+=36)e=d(e/35);return d(i+36*e/(e+38))}function $(e){var t,s,i,o,r,n,a,c,h,u,p,f=[],m=e.length,w=0,y=128,v=72;for((s=e.lastIndexOf("-"))<0&&(s=0),i=0;i<s;++i)e.charCodeAt(i)>=128&&g("not-basic"),f.push(e.charCodeAt(i));for(o=s>0?s+1:0;o<m;){for(r=w,n=1,a=36;o>=m&&g("invalid-input"),((c=(p=e.charCodeAt(o++))-48<10?p-22:p-65<26?p-65:p-97<26?p-97:36)>=36||c>d((l-w)/n))&&g("overflow"),w+=c*n,!(c<(h=a<=v?1:a>=v+26?26:a-v));a+=36)n>d(l/(u=36-h))&&g("overflow"),n*=u;v=S(w-r,t=f.length+1,0==r),d(w/t)>l-y&&g("overflow"),y+=d(w/t),w%=t,f.splice(w++,0,y)}return k(f)}function b(e){var t,s,i,o,r,n,a,c,h,u,p,m,w,k,$,b=[];for(m=(e=y(e)).length,t=128,s=0,r=72,n=0;n<m;++n)(p=e[n])<128&&b.push(f(p));for(i=o=b.length,o&&b.push("-");i<m;){for(a=l,n=0;n<m;++n)(p=e[n])>=t&&p<a&&(a=p);for(a-t>d((l-s)/(w=i+1))&&g("overflow"),s+=(a-t)*w,t=a,n=0;n<m;++n)if((p=e[n])<t&&++s>l&&g("overflow"),p==t){for(c=s,h=36;!(c<(u=h<=r?1:h>=r+26?26:h-r));h+=36)$=c-u,k=36-u,b.push(f(v(u+$%k,0))),c=d($/k);b.push(f(v(c,0))),r=S(s,w,i==o),s=0,++i}++s,++t}return b.join("")}if(n={version:"1.3.2",ucs2:{decode:y,encode:k},decode:$,encode:b,toASCII:function(e){return w(e,(function(e){return h.test(e)?"xn--"+b(e):e}))},toUnicode:function(e){return w(e,(function(e){return c.test(e)?$(e.slice(4).toLowerCase()):e}))}},i&&o)if(e.exports==i)o.exports=n;else for(a in n)n.hasOwnProperty(a)&&(i[a]=n[a]);else s.punycode=n}(M)}));function W(e,t){return Object.prototype.hasOwnProperty.call(e,t)}var D=function(e,t,s,i){t=t||"&",s=s||"=";var o={};if("string"!==typeof e||0===e.length)return o;var r=/\+/g;e=e.split(t);var n=1e3;i&&"number"===typeof i.maxKeys&&(n=i.maxKeys);var a=e.length;n>0&&a>n&&(a=n);for(var l=0;l<a;++l){var c,h,u,p,d=e[l].replace(r,"%20"),f=d.indexOf(s);f>=0?(c=d.substr(0,f),h=d.substr(f+1)):(c=d,h=""),u=decodeURIComponent(c),p=decodeURIComponent(h),W(o,u)?Array.isArray(o[u])?o[u].push(p):o[u]=[o[u],p]:o[u]=p}return o},Q=function(e){switch(typeof e){case"string":return e;case"boolean":return e?"true":"false";case"number":return isFinite(e)?e:"";default:return""}},U=function(e,t,s,i){return t=t||"&",s=s||"=",null===e&&(e=void 0),"object"===typeof e?Object.keys(e).map((function(i){var o=encodeURIComponent(Q(i))+s;return Array.isArray(e[i])?e[i].map((function(e){return o+encodeURIComponent(Q(e))})).join(t):o+encodeURIComponent(Q(e[i]))})).join(t):i?encodeURIComponent(Q(i))+s+encodeURIComponent(Q(e)):""},z=F((function(e,t){t.decode=t.parse=D,t.encode=t.stringify=U})),L=function(e,t){return ie(e,!1,!0).resolve(t)};function J(){this.protocol=null,this.slashes=null,this.auth=null,this.host=null,this.port=null,this.hostname=null,this.hash=null,this.search=null,this.query=null,this.pathname=null,this.path=null,this.href=null}var H=/^([a-z0-9.+-]+:)/i,G=/:[0-9]*$/,B=["{","}","|","\\","^","`"].concat(["<",">",'"',"`"," ","\r","\n","\t"]),V=["'"].concat(B),K=["%","/","?",";","#"].concat(V),X=["/","?","#"],Y=/^[a-z0-9A-Z_-]{0,63}$/,Z=/^([a-z0-9A-Z_-]{0,63})(.*)$/,ee={javascript:!0,"javascript:":!0},te={javascript:!0,"javascript:":!0},se={http:!0,https:!0,ftp:!0,gopher:!0,file:!0,"http:":!0,"https:":!0,"ftp:":!0,"gopher:":!0,"file:":!0};function ie(e,t,s){if(e&&re(e)&&e instanceof J)return e;var i=new J;return i.parse(e,t,s),i}function oe(e){return"string"===typeof e}function re(e){return"object"===typeof e&&null!==e}function ne(e){return null===e}J.prototype.parse=function(e,t,s){if(!oe(e))throw new TypeError("Parameter 'url' must be a string, not "+typeof e);var i=e;i=i.trim();var o=H.exec(i);if(o){var r=(o=o[0]).toLowerCase();this.protocol=r,i=i.substr(o.length)}if(s||o||i.match(/^\/\/[^@\/]+@[^@\/]+/)){var n="//"===i.substr(0,2);!n||o&&te[o]||(i=i.substr(2),this.slashes=!0)}if(!te[o]&&(n||o&&!se[o])){for(var a,l,c=-1,h=0;h<X.length;h++){-1!==(u=i.indexOf(X[h]))&&(-1===c||u<c)&&(c=u)}-1!==(l=-1===c?i.lastIndexOf("@"):i.lastIndexOf("@",c))&&(a=i.slice(0,l),i=i.slice(l+1),this.auth=decodeURIComponent(a)),c=-1;for(h=0;h<K.length;h++){var u;-1!==(u=i.indexOf(K[h]))&&(-1===c||u<c)&&(c=u)}-1===c&&(c=i.length),this.host=i.slice(0,c),i=i.slice(c),this.parseHost(),this.hostname=this.hostname||"";var p="["===this.hostname[0]&&"]"===this.hostname[this.hostname.length-1];if(!p)for(var d=this.hostname.split(/\./),f=(h=0,d.length);h<f;h++){var g=d[h];if(g&&!g.match(Y)){for(var m="",w=0,y=g.length;w<y;w++)g.charCodeAt(w)>127?m+="x":m+=g[w];if(!m.match(Y)){var k=d.slice(0,h),v=d.slice(h+1),S=g.match(Z);S&&(k.push(S[1]),v.unshift(S[2])),v.length&&(i="/"+v.join(".")+i),this.hostname=k.join(".");break}}}if(this.hostname.length>255?this.hostname="":this.hostname=this.hostname.toLowerCase(),!p){var $=this.hostname.split("."),b=[];for(h=0;h<$.length;++h){var I=$[h];b.push(I.match(/[^A-Za-z0-9_-]/)?"xn--"+q.encode(I):I)}this.hostname=b.join(".")}var _=this.port?":"+this.port:"",E=this.hostname||"";this.host=E+_,this.href+=this.host,p&&(this.hostname=this.hostname.substr(1,this.hostname.length-2),"/"!==i[0]&&(i="/"+i))}if(!ee[r])for(h=0,f=V.length;h<f;h++){var P=V[h],T=encodeURIComponent(P);T===P&&(T=escape(P)),i=i.split(P).join(T)}var j=i.indexOf("#");-1!==j&&(this.hash=i.substr(j),i=i.slice(0,j));var x=i.indexOf("?");if(-1!==x?(this.search=i.substr(x),this.query=i.substr(x+1),t&&(this.query=z.parse(this.query)),i=i.slice(0,x)):t&&(this.search="",this.query={}),i&&(this.pathname=i),se[r]&&this.hostname&&!this.pathname&&(this.pathname="/"),this.pathname||this.search){_=this.pathname||"",I=this.search||"";this.path=_+I}return this.href=this.format(),this},J.prototype.format=function(){var e=this.auth||"";e&&(e=(e=encodeURIComponent(e)).replace(/%3A/i,":"),e+="@");var t=this.protocol||"",s=this.pathname||"",i=this.hash||"",o=!1,r="";this.host?o=e+this.host:this.hostname&&(o=e+(-1===this.hostname.indexOf(":")?this.hostname:"["+this.hostname+"]"),this.port&&(o+=":"+this.port)),this.query&&re(this.query)&&Object.keys(this.query).length&&(r=z.stringify(this.query));var n=this.search||r&&"?"+r||"";return t&&":"!==t.substr(-1)&&(t+=":"),this.slashes||(!t||se[t])&&!1!==o?(o="//"+(o||""),s&&"/"!==s.charAt(0)&&(s="/"+s)):o||(o=""),i&&"#"!==i.charAt(0)&&(i="#"+i),n&&"?"!==n.charAt(0)&&(n="?"+n),t+o+(s=s.replace(/[?#]/g,(function(e){return encodeURIComponent(e)})))+(n=n.replace("#","%23"))+i},J.prototype.resolve=function(e){return this.resolveObject(ie(e,!1,!0)).format()},J.prototype.resolveObject=function(e){if(oe(e)){var t=new J;t.parse(e,!1,!0),e=t}var s=new J;if(Object.keys(this).forEach((function(e){s[e]=this[e]}),this),s.hash=e.hash,""===e.href)return s.href=s.format(),s;if(e.slashes&&!e.protocol)return Object.keys(e).forEach((function(t){"protocol"!==t&&(s[t]=e[t])})),se[s.protocol]&&s.hostname&&!s.pathname&&(s.path=s.pathname="/"),s.href=s.format(),s;if(e.protocol&&e.protocol!==s.protocol){if(!se[e.protocol])return Object.keys(e).forEach((function(t){s[t]=e[t]})),s.href=s.format(),s;if(s.protocol=e.protocol,e.host||te[e.protocol])s.pathname=e.pathname;else{for(var i=(e.pathname||"").split("/");i.length&&!(e.host=i.shift()););e.host||(e.host=""),e.hostname||(e.hostname=""),""!==i[0]&&i.unshift(""),i.length<2&&i.unshift(""),s.pathname=i.join("/")}if(s.search=e.search,s.query=e.query,s.host=e.host||"",s.auth=e.auth,s.hostname=e.hostname||e.host,s.port=e.port,s.pathname||s.search){var o=s.pathname||"",r=s.search||"";s.path=o+r}return s.slashes=s.slashes||e.slashes,s.href=s.format(),s}var n=s.pathname&&"/"===s.pathname.charAt(0),a=e.host||e.pathname&&"/"===e.pathname.charAt(0),l=a||n||s.host&&e.pathname,c=l,h=s.pathname&&s.pathname.split("/")||[],u=(i=e.pathname&&e.pathname.split("/")||[],s.protocol&&!se[s.protocol]);if(u&&(s.hostname="",s.port=null,s.host&&(""===h[0]?h[0]=s.host:h.unshift(s.host)),s.host="",e.protocol&&(e.hostname=null,e.port=null,e.host&&(""===i[0]?i[0]=e.host:i.unshift(e.host)),e.host=null),l=l&&(""===i[0]||""===h[0])),a)s.host=e.host||""===e.host?e.host:s.host,s.hostname=e.hostname||""===e.hostname?e.hostname:s.hostname,s.search=e.search,s.query=e.query,h=i;else if(i.length)h||(h=[]),h.pop(),h=h.concat(i),s.search=e.search,s.query=e.query;else if(null!=e.search){if(u)s.hostname=s.host=h.shift(),(m=!!(s.host&&s.host.indexOf("@")>0)&&s.host.split("@"))&&(s.auth=m.shift(),s.host=s.hostname=m.shift());return s.search=e.search,s.query=e.query,ne(s.pathname)&&ne(s.search)||(s.path=(s.pathname?s.pathname:"")+(s.search?s.search:"")),s.href=s.format(),s}if(!h.length)return s.pathname=null,s.search?s.path="/"+s.search:s.path=null,s.href=s.format(),s;for(var p=h.slice(-1)[0],d=(s.host||e.host)&&("."===p||".."===p)||""===p,f=0,g=h.length;g>=0;g--)"."==(p=h[g])?h.splice(g,1):".."===p?(h.splice(g,1),f++):f&&(h.splice(g,1),f--);if(!l&&!c)for(;f--;f)h.unshift("..");!l||""===h[0]||h[0]&&"/"===h[0].charAt(0)||h.unshift(""),d&&"/"!==h.join("/").substr(-1)&&h.push("");var m,w=""===h[0]||h[0]&&"/"===h[0].charAt(0);u&&(s.hostname=s.host=w?"":h.length?h.shift():"",(m=!!(s.host&&s.host.indexOf("@")>0)&&s.host.split("@"))&&(s.auth=m.shift(),s.host=s.hostname=m.shift()));return(l=l||s.host&&h.length)&&!w&&h.unshift(""),h.length?s.pathname=h.join("/"):(s.pathname=null,s.path=null),ne(s.pathname)&&ne(s.search)||(s.path=(s.pathname?s.pathname:"")+(s.search?s.search:"")),s.auth=e.auth||s.auth,s.slashes=s.slashes||e.slashes,s.href=s.format(),s},J.prototype.parseHost=function(){var e=this.host,t=G.exec(e);t&&(":"!==(t=t[0])&&(this.port=t.substr(1)),e=e.substr(0,e.length-t.length)),e&&(this.hostname=e)};var ae="3.0.1759";w.defaults.validateStatus=e=>e<=504;const le=function(){const e=(e,t)=>{e.headers||(e.headers={});let s=t;if(s||(s={}),!s.apikey)return;if(e.headers["X-EPI2ME-ApiKey"]=s.apikey,!s.apisecret)return;e.headers["X-EPI2ME-SignatureDate"]=(new Date).toISOString(),e.url.match(/^https:/)&&(e.url=e.url.replace(/:443/,"")),e.url.match(/^http:/)&&(e.url=e.url.replace(/:80/,""));const i=[e.url,Object.keys(e.headers).sort().filter(e=>e.match(/^x-epi2me/i)).map(t=>`${t}:${e.headers[t]}`).join("\n")].join("\n"),o=y.createHmac("sha1",s.apisecret).update(i).digest("hex");e.headers["X-EPI2ME-SignatureV0"]=o},t=async e=>{const t=e?e.data:null;if(!t)return Promise.reject(new Error("unexpected non-json response"));if(e&&e.status>=400){let s=`Network error ${e.status}`;return t.error&&(s=t.error),504===e.status&&(s="Please check your network connection and try again."),Promise.reject(new Error(s))}return t.error?Promise.reject(new Error(t.error)):Promise.resolve(t)};return{version:"3.0.1759",headers:(t,i)=>{const{log:o}=s({log:{debug:()=>{}}},i);let r=i;if(r||(r={}),t.headers=s({Accept:"application/json","Content-Type":"application/json","X-EPI2ME-Client":r.user_agent||"api","X-EPI2ME-Version":r.agent_version||le.version},t.headers,r.headers),"signing"in r&&!r.signing||e(t,r),r.proxy){const e=r.proxy.match(/https?:\/\/((\S+):(\S+)@)?(\S+):(\d+)/),s=e[2],i=e[3],n={host:e[4],port:e[5]};s&&i&&(n.proxyAuth=`${s}:${i}`),r.proxy.match(/^https/)?(o.debug("using HTTPS over HTTPS proxy",JSON.stringify(n)),t.httpsAgent=k({proxy:n})):(o.debug("using HTTPS over HTTP proxy",JSON.stringify(n)),t.httpsAgent=v({proxy:n})),t.proxy=!1}},head:async(e,t)=>{const{log:i}=s({log:{debug:()=>{}}},t);let o,r=t.url,n=e;t.skip_url_mangle?o=n:(n=`/${n}`,r=r.replace(/\/+$/,""),n=n.replace(/\/+/g,"/"),o=r+n);const a={url:o,gzip:!0};let l;le.headers(a,t);try{if(i.debug(`HEAD ${a.url}`),l=await w.head(a.url,a),l&&l.status>=400){let e=`Network error ${l.status}`;return 504===l.status&&(e="Please check your network connection and try again."),Promise.reject(new Error(e))}}catch(c){return Promise.reject(c)}return Promise.resolve(l)},get:async(e,i)=>{const{log:o}=s({log:{debug:()=>{}}},i);let r,n=i.url,a=e;i.skip_url_mangle?r=a:(a=`/${a}`,n=n.replace(/\/+$/,""),a=a.replace(/\/+/g,"/"),r=n+a);const l={url:r,gzip:!0};let c;le.headers(l,i);try{o.debug(`GET ${l.url}`),c=await w.get(l.url,l)}catch(h){return Promise.reject(h)}return t(c,i)},post:async(e,i,o)=>{const{log:r}=s({log:{debug:()=>{}}},o);let n=o.url;n=n.replace(/\/+$/,"");const a={url:`${n}/${e.replace(/\/+/g,"/")}`,gzip:!0,data:i,headers:{}};if(o.legacy_form){const e=[],t=s({json:JSON.stringify(i)},i);Object.keys(t).sort().forEach(s=>{e.push(`${s}=${escape(t[s])}`)}),a.data=e.join("&"),a.headers["Content-Type"]="application/x-www-form-urlencoded"}le.headers(a,o);const{data:l}=a;let c;delete a.data;try{r.debug(`POST ${a.url}`),c=await w.post(a.url,l,a)}catch(h){return Promise.reject(h)}return o.handler?o.handler(c):t(c,o)},put:async(e,i,o,r)=>{const{log:n}=s({log:{debug:()=>{}}},r);let a=r.url;a=a.replace(/\/+$/,"");const l={url:`${a}/${e.replace(/\/+/g,"/")}/${i}`,gzip:!0,data:o,headers:{}};if(r.legacy_form){const e=[],t=s({json:JSON.stringify(o)},o);Object.keys(t).sort().forEach(s=>{e.push(`${s}=${escape(t[s])}`)}),l.data=e.join("&"),l.headers["Content-Type"]="application/x-www-form-urlencoded"}le.headers(l,r);const{data:c}=l;let h;delete l.data;try{n.debug(`PUT ${l.url}`),h=await w.put(l.url,c,l)}catch(u){return Promise.reject(u)}return t(h,r)},convertResponseToObject(e){if("object"===typeof e)return e;try{return JSON.parse(e)}catch(t){throw new Error(`exception parsing chain JSON ${String(t)}`)}}}}();le.pipe=async(e,s,i,o)=>{let r=i.url,n=`/${e}`;r=r.replace(/\/+$/,""),n=n.replace(/\/+/g,"/");const a={url:r+n,gzip:!0,headers:{"Accept-Encoding":"gzip",Accept:"application/gzip"}};return le.headers(a,i),i.proxy&&(a.proxy=i.proxy),o&&(a.onUploadProgress=o),a.responseType="stream",new Promise((e,i)=>{w.get(a.url,a).then(o=>{const r=t.createWriteStream(s);o.data.pipe(r),r.on("finish",()=>{e(s)}),r.on("error",e=>{i(new Error(`writer failed ${String(e)}`))})}).catch(e=>{i(e)})})};let ce=0;le.getFileID=()=>(ce+=1,`FILE_${ce}`),le.lsRecursive=async(e,s,o)=>{let r=e;const n=t.statSync(s);if(o){if(await o(s,n))return[]}return n.isDirectory()?t.readdir(s).then(e=>e.map(e=>g.join(s,e))).then(e=>Promise.all(e.map(e=>le.lsRecursive(r,e,o)))).then(e=>i(e)):(n.isFile()&&r===s&&(r=g.dirname(s)),[{name:g.parse(s).base,path:s,relative:s.replace(r,""),size:n.size,id:le.getFileID()}])},le.loadInputFiles=async({inputFolders:e,outputFolder:t,filetype:s},i,o)=>{let r=s;r instanceof Array||(r=[r]),r=r.map(e=>e&&0!==e.indexOf(".")?`.${e}`:e);const n=async(e,s)=>{const i=g.basename(e),n=[new Promise((t,s)=>"downloads"===i||"skip"===i||"fail"===i||"fastq_fail"===i||"tmp"===i?s(new Error(`${e} failed basic filename`)):t("basic ok")),new Promise((o,n)=>{const a=r.length?new RegExp(`(?:${r.join("|")})$`):null;return e.split(g.sep).filter(e=>e.match(/^[.]/)).length||t&&i===g.basename(t)||a&&!e.match(a)&&s.isFile()?n(new Error(`${e} failed extended filename`)):o("extended ok")}),o?new Promise((t,s)=>{o(e).then(i=>i?s(new Error(`${e} failed extraFilter`)):t("extra ok"))}):Promise.resolve("extra skip")];return Promise.all(n).then(()=>null).catch(()=>"exclude")};return(await Promise.all(e.map(e=>le.lsRecursive(e,e,n)))).reduce((e,t)=>[...e,...t.filter(e=>!!e)],[])},le.stripFile=e=>[g.dirname(e),g.basename(e)];class he{constructor(e,i,o){const r=s({},i);this.options=r,this.log=o;const{idWorkflowInstance:n,inputFolders:a}=r;o.debug(`setting up ${e}/db.sqlite for ${n}`),this.db=t.mkdirp(e).then(()=>(this.log.debug(`opening ${e}/db.sqlite`),m.open(g.join(e,"db.sqlite")).then(async t=>{this.log.debug(`opened ${e}/db.sqlite`),await t.migrate({migrationsPath:g.join(__dirname,"migrations")});const s=a.map(()=>"(?)").join(",");try{return await Promise.all([t.run("INSERT INTO meta (version, idWorkflowInstance) VALUES(?, ?)",ae,n),t.run(`INSERT INTO folders (folder_path) VALUES ${s}`,a)]),Promise.resolve(t)}catch(i){return this.log.error(i),Promise.reject(i)}}))).catch(e=>{throw this.log.error(e),e})}async uploadFile(e){const t=await this.db,[s,i]=le.stripFile(e);return await t.run("INSERT OR IGNORE INTO folders (folder_path) VALUES (?)",s),t.run("INSERT INTO uploads(filename, path_id) VALUES(?, (SELECT folder_id FROM folders WHERE folder_path = ?))",i,s)}async skipFile(e){const t=await this.db,[s,i]=le.stripFile(e);return await t.run("INSERT OR IGNORE INTO folders (folder_path) VALUES (?)",s),t.run("INSERT INTO skips(filename, path_id) VALUES(?, (SELECT folder_id FROM folders WHERE folder_path = ?))",i,s)}async splitFile(e,t){const s=await this.db,[i,o]=le.stripFile(e),r=le.stripFile(t)[1];return await s.run("INSERT OR IGNORE INTO folders (folder_path) VALUES (?)",i),s.run("INSERT INTO splits(filename, parent, child_path_id, start, end) VALUES(?, ?, (SELECT folder_id FROM folders WHERE folder_path = ?), CURRENT_TIMESTAMP, NULL)",o,r,i)}async splitDone(e){const t=await this.db,[s,i]=le.stripFile(e);return t.run("UPDATE splits SET end=CURRENT_TIMESTAMP WHERE filename=? AND child_path_id=(SELECT folder_id FROM folders WHERE folder_path=?)",i,s)}async splitClean(){return(await this.db).all("SELECT splits.filename, folders.folder_path FROM splits INNER JOIN folders ON folders.folder_id = splits.child_path_id WHERE end IS NULL").then(e=>{if(!e)return this.log.info("no split files to clean"),Promise.resolve([]);this.log.info(`cleaning ${e.length} split files`),this.log.debug(`going to clean: ${e.map(e=>e.filename).join(" ")}`);const s=e.map(e=>t.unlink(g.join(e.folder_path,e.filename)).catch(()=>{console.warn(`Failed to cleanup ${g.join(e.folder_path,e.filename)}`)}));return Promise.all(s)})}async seenUpload(e){const t=await this.db,[s,i]=le.stripFile(e);return Promise.all([t.get("SELECT * FROM uploads u INNER JOIN folders ON folders.folder_id = u.path_id WHERE u.filename=? AND folders.folder_path=? LIMIT 1",[i,s]),t.get("SELECT * FROM skips s INNER JOIN folders ON folders.folder_id = s.path_id WHERE s.filename=? AND folders.folder_path=? LIMIT 1",i,s)]).then(e=>o(e,void 0).length)}}var ue="https://epi2me.nanoporetech.com",pe={local:!1,url:ue,user_agent:"EPI2ME API",region:"eu-west-1",sessionGrace:5,uploadTimeout:1200,downloadTimeout:1200,fileCheckInterval:5,downloadCheckInterval:3,stateCheckInterval:60,inFlightDelay:600,waitTimeSeconds:20,waitTokenError:30,transferPoolSize:3,downloadMode:"data+telemetry",filetype:[".fastq",".fq",".fastq.gz",".fq.gz"],signing:!0,sampleDirectory:"/data"};const de="\npage\npages\nhasNext\nhasPrevious\ntotalCount\n",fe="\nidWorkflowInstance\nstartDate\nworkflowImage{\n  workflow\n  {\n    rev\n    name\n  }\n}\n",ge=function(){const e=(e,t)=>{e.headers||(e.headers={});let s=t;if(s||(s={}),!s.apikey||!s.apisecret)return;e.headers["X-EPI2ME-APIKEY"]=s.apikey,e.headers["X-EPI2ME-SIGNATUREDATE"]=(new Date).toISOString();const i=[Object.keys(e.headers).sort().filter(e=>e.match(/^x-epi2me/i)).map(t=>`${t}:${e.headers[t]}`).join("\n"),e.body].join("\n"),o=y.createHmac("sha1",s.apisecret).update(i).digest("hex");e.headers["X-EPI2ME-SIGNATUREV0"]=o};return{version:"3.0.1759",setHeaders:(t,i)=>{const{log:o}=s({log:{debug:()=>{}}},i);let r=i;if(r||(r={}),t.headers=s({Accept:"application/json","Content-Type":"application/json","X-EPI2ME-CLIENT":r.user_agent||"api","X-EPI2ME-VERSION":r.agent_version||ge.version},t.headers,r.headers),"signing"in r&&!r.signing||e(t,r),r.proxy){const e=r.proxy.match(/https?:\/\/((\S+):(\S+)@)?(\S+):(\d+)/),s=e[2],i=e[3],n={host:e[4],port:e[5]};s&&i&&(n.proxyAuth=`${s}:${i}`),r.proxy.match(/^https/)?(o.debug("using HTTPS over HTTPS proxy",JSON.stringify(n)),t.httpsAgent=k({proxy:n})):(o.debug("using HTTPS over HTTP proxy",JSON.stringify(n)),t.httpsAgent=v({proxy:n})),t.proxy=!1}}}}(),me=j(w),we=(e,t)=>{const{apikey:s,apisecret:i}=t.headers.keys;return delete t.headers.keys,ge.setHeaders(t,{apikey:s,apisecret:i,signing:!0}),me(e,t)},ye=new _({link:new E(e=>{const{apikey:t,apisecret:s,url:i}=e.getContext(),o=T({uri:L(i,"/graphql"),fetch:we,headers:{keys:{apikey:t,apisecret:s}}});return P(o,e)}),cache:new I});class ke{constructor(e){this.createContext=e=>{const{apikey:t,apisecret:i,url:o}=this.options;return s({apikey:t,apisecret:i,url:o},e)},this.query=e=>({context:t={},variables:s={},options:i={}}={})=>{const o=this.createContext(t);let r;return r="string"===typeof e?b`
        ${e}
      `:"function"===typeof e?b`
        ${e(de)}
      `:e,this.client.query(Object.assign(Object.assign({query:r,variables:s},i),{context:o}))},this.mutate=e=>({context:t={},variables:s={},options:i={}}={})=>{const o=this.createContext(t);let r;return r="string"===typeof e?b`
        ${e}
      `:e,this.client.mutate(Object.assign(Object.assign({mutation:r,variables:s},i),{context:o}))},this.resetCache=()=>{this.client.resetStore()},this.workflows=this.query(b`
    query allWorkflows($page: Int, $pageSize: Int, $isActive: Int, $orderBy: String, $region: String) {
      allWorkflows(page: $page, pageSize: $pageSize, isActive: $isActive, orderBy: $orderBy, region: $region) {
        ${de}
        results {
          ${"\nidWorkflow\nname\ndescription\nsummary\nrev\n"}
        }
      }
    }
  `),this.workflowPages=async e=>{let t=e,s=await this.workflows({variables:{page:t}});const i=async e=>(t=e,s=await this.workflows({variables:{page:t}}),s);return{data:s,next:()=>i(t+1),previous:()=>i(t-1),first:()=>i(1),last:()=>i(0)}},this.workflow=this.query(b`
    query workflow($idWorkflow: ID!) {
      workflow(idWorkflow: $idWorkflow) {
        ${"\nidWorkflow\nname\ndescription\nsummary\nrev\n"}
      }
    }
   `),this.workflowInstances=this.query(b`
  query allWorkflowInstances($page: Int, $pageSize: Int, $shared: Boolean, $idUser: ID, $orderBy: String) {
    allWorkflowInstances(page: $page, pageSize: $pageSize, shared: $shared, idUser: $idUser, orderBy: $orderBy) {
      ${de}
      results {
        ${fe}
      }
    }
  }
   `),this.workflowInstance=this.query(b`
      query workflowInstance($idWorkflowInstance: ID!) {
        workflowInstance(idWorkflowInstance: $idWorkflowInstance) {
          ${fe}
        }
      }
   `),this.startWorkflow=this.mutate(b`
    mutation startWorkflow(
      $idWorkflow: ID!
      $computeAccountId: ID!
      $storageAccountId: ID
      $isConsentedHuman: Boolean = false
      $idDataset: ID
      $storeResults: Boolean = false
      $userDefined: GenericScalar
      $instanceAttributes: [GenericScalar]
      $region: String
    ) {
      startData: startWorkflowInstance(
        idWorkflow: $idWorkflow
        computeAccountId: $computeAccountId
        storageAccountId: $storageAccountId
        isConsentedHuman: $isConsentedHuman
        idDataset: $idDataset
        storeResults: $storeResults
        userDefined: $userDefined
        instanceAttributes: $instanceAttributes
        region: $region
      ) {
        bucket
        idUser
        remoteAddr
        instance {
          idWorkflowInstance
          chain
          keyId
          outputqueue
          mappedTelemetry
          workflowImage {
            inputqueue
            workflow {
              idWorkflow
            }
            region {
              name
            }
          }
        }
      }
    }
  `),this.stopWorkflow=this.mutate(b`
    mutation stopWorkflowInstance($idWorkflowInstance: ID!) {
      stopData: stopWorkflowInstance(idWorkflowInstance: $idWorkflowInstance) {
        success
        message
      }
    }
  `),this.instanceToken=this.mutate(b`
    mutation getInstanceToken($idWorkflowInstance: ID!) {
      token: getInstanceToken(idWorkflowInstance: $idWorkflowInstance) {
        id_workflow_instance: idWorkflowInstance
        accessKeyId
        secretAccessKey
        sessionToken
        expiration
        region
      }
    }
  `),this.user=this.query(b`
    query user {
      me {
        username
        realname
        useraccountSet {
          idUserAccount
        }
      }
    }
  `),this.updateUser=this.mutate(b`
    mutation updateUser($idRegionPreferred: ID!) {
      updateUser(idRegionPreferred: $idRegionPreferred) {
        idRegionPreferred
      }
    }
  `),this.register=this.mutate(b`
    mutation registerToken($code: String!, $description: String) {
      registerToken(code: $code, description: $description) {
        apikey
        apisecret
        description
      }
    }
  `),this.status=this.query(b`
    query status {
      status {
        portalVersion
        remoteAddr
        serverTime
        minimumAgent
        dbVersion
      }
    }
  `),this.healthCheck=()=>le.get("/status",Object.assign(Object.assign({},this.options),{log:{debug:()=>{}}})),this.regions=this.query(b`
    query regions {
      regions {
        idRegion
        description
        name
      }
    }
  `),this.options=r({agent_version:le.version,local:!1,url:ue,user_agent:"EPI2ME API",signing:!0},e),this.options.url=this.options.url.replace(/:\/\//,"://graphql."),this.options.url=this.options.url.replace(/\/$/,""),this.log=this.options.log,this.client=ye}}const ve=(e,t)=>{const s=["","K","M","G","T","P","E","Z"];let i=t||0,o=e||0;return o>=1e3?(o/=1e3,i+=1,i>=s.length?"???":ve(o,i)):0===i?`${o}${s[i]}`:`${o.toFixed(1)}${s[i]}`};class Se{constructor(e){this.allProfileData={},this.defaultEndpoint=process.env.METRICHOR||pe.url,e&&(this.allProfileData=s({profiles:{}},e)),this.allProfileData.endpoint&&(this.defaultEndpoint=this.allProfileData.endpoint)}profile(e){return e?s({endpoint:this.defaultEndpoint},s({profiles:{}},this.allProfileData).profiles[e]):{}}profiles(){return Object.keys(this.allProfileData.profiles||{})}}class $e{constructor(e){this.options=r({agent_version:le.version,local:!1,url:ue,user_agent:"EPI2ME API",signing:!0},e),this.log=this.options.log,this.cachedResponses={}}async list(e){const t=e.match(/^[a-z_]+/i)[0];return le.get(e,this.options).then(e=>e[`${t}s`])}async read(e,t){return le.get(`${e}/${t}`,this.options)}async user(){return this.options.local?{accounts:[{id_user_account:"none",number:"NONE",name:"None"}]}:le.get("user",this.options)}async status(){return le.get("status",this.options)}async jwt(){return le.post("authenticate",{},s({handler:e=>e.headers["x-epi2me-jwt"]?Promise.resolve(e.headers["x-epi2me-jwt"]):Promise.reject(new Error("failed to fetch JWT"))},this.options))}async instanceToken(e,t){return le.post("token",s(t,{id_workflow_instance:e}),r({},this.options,{legacy_form:!0}))}async installToken(e){return le.post("token/install",{id_workflow:e},r({},this.options,{legacy_form:!0}))}async attributes(){return this.list("attribute")}async workflows(){return this.list("workflow")}async amiImages(){if(this.options.local)throw new Error("amiImages unsupported in local mode");return this.list("ami_image")}async amiImage(e,t){let s,i,o;if(e&&t instanceof Object?(s=e,i=t,o="update"):e instanceof Object&&!t?(i=e,o="create"):(o="read",s=e),this.options.local)throw new Error("ami_image unsupported in local mode");if("update"===o)return le.put("ami_image",s,i,this.options);if("create"===o)return le.post("ami_image",i,this.options);if(!s)throw new Error("no id_ami_image specified");return this.read("ami_image",s)}async workflow(e,t,i){let o,r,a,l;if(e&&t&&i instanceof Function?(o=e,r=t,a=i,l="update"):e&&t instanceof Object&&!(t instanceof Function)?(o=e,r=t,l="update"):e instanceof Object&&t instanceof Function?(r=e,a=t,l="create"):e instanceof Object&&!t?(r=e,l="create"):(l="read",o=e,a=t instanceof Function?t:null),"update"===l)try{const e=await le.put("workflow",o,r,this.options);return a?a(null,e):Promise.resolve(e)}catch(p){return a?a(p):Promise.reject(p)}if("create"===l)try{const e=await le.post("workflow",r,this.options);return a?a(null,e):Promise.resolve(e)}catch(p){return a?a(p):Promise.reject(p)}if(!o){const e=new Error("no workflow id specified");return a?a(e):Promise.reject(e)}const c={};try{const e=await this.read("workflow",o);if(e.error)throw new Error(e.error);s(c,e)}catch(p){return this.log.error(`${o}: error fetching workflow ${String(p)}`),a?a(p):Promise.reject(p)}s(c,{params:{}});try{const e=await le.get(`workflow/config/${o}`,this.options);if(e.error)throw new Error(e.error);s(c,e)}catch(p){return this.log.error(`${o}: error fetching workflow config ${String(p)}`),a?a(p):Promise.reject(p)}const h=n(c.params,{widget:"ajax_dropdown"}),u=[...h.map((e,t)=>{const s=h[t];return new Promise((e,t)=>{const i=s.values.source.replace("{{EPI2ME_HOST}}","").replace(/&?apikey=\{\{EPI2ME_API_KEY\}\}/,"");le.get(i,this.options).then(t=>{const i=t[s.values.data_root];return i&&(s.values=i.map(e=>({label:e[s.values.items.label_key],value:e[s.values.items.value_key]}))),e()}).catch(e=>(this.log.error(`failed to fetch ${i}`),t(e)))})})];try{return await Promise.all(u),a?a(null,c):Promise.resolve(c)}catch(p){return this.log.error(`${o}: error fetching config and parameters ${String(p)}`),a?a(p):Promise.reject(p)}}async startWorkflow(e){return le.post("workflow_instance",e,r({},this.options,{legacy_form:!0}))}async stopWorkflow(e){return le.put("workflow_instance/stop",e,null,r({},this.options,{legacy_form:!0}))}async workflowInstances(e){return e&&e.run_id?le.get(`workflow_instance/wi?show=all&columns[0][name]=run_id;columns[0][searchable]=true;columns[0][search][regex]=true;columns[0][search][value]=${e.run_id};`,this.options).then(e=>e.data.map(e=>({id_workflow_instance:e.id_ins,id_workflow:e.id_flo,run_id:e.run_id,description:e.desc,rev:e.rev}))):this.list("workflow_instance")}async workflowInstance(e){return this.read("workflow_instance",e)}async workflowConfig(e){return le.get(`workflow/config/${e}`,this.options)}async register(e,t){return le.put("reg",e,{description:t||`${p.userInfo().username}@${p.hostname()}`},r({},this.options,{signing:!1}))}async datasets(e){let t=e;return t||(t={}),t.show||(t.show="mine"),this.list(`dataset?show=${t.show}`)}async dataset(e){return this.options.local?this.datasets().then(t=>t.find(t=>t.id_dataset===e)):this.read("dataset",e)}async fetchContent(e){const t=r({},this.options,{skip_url_mangle:!0,headers:{"Content-Type":""}});let s;try{if(s=(await le.head(e,t)).headers.etag,s&&this.cachedResponses[e]&&this.cachedResponses[e].etag===s)return this.cachedResponses[e].response}catch(o){this.log.warn(`Failed to HEAD request ${e}: ${String(o)}`)}const i=await le.get(e,t);return s&&(this.cachedResponses[e]={etag:s,response:i}),i}}class be{constructor(e,t){this.debounces={},this.debounceWindow=s({debounceWindow:2e3},t).debounceWindow,this.log=s({log:{debug:()=>{}}},t).log,e.jwt().then(e=>{this.socket=x(t.url,{transportOptions:{polling:{extraHeaders:{Cookie:`x-epi2me-jwt=${e}`}}}}),this.socket.on("connect",()=>{this.log.debug("socket ready")})}).catch(e=>{this.log.error("socket connection failed - JWT authentication error")})}debounce(e,t){const i=s(e)._uuid;if(i){if(this.debounces[i])return;this.debounces[i]=1,setTimeout(()=>{delete this.debounces[i]},this.debounceWindow)}t&&t(e)}watch(e,t){if(!this.socket)return this.log.debug(`socket not ready. requeueing watch on ${e}`),void setTimeout(()=>{this.watch(e,t)},1e3);this.socket.on(e,e=>this.debounce(e,t))}emit(e,t){if(!this.socket)return this.log.debug(`socket not ready. requeueing emit on ${e}`),void setTimeout(()=>{this.emit(e,t)},1e3);this.log.debug(`socket emit ${e} ${JSON.stringify(t)}`),this.socket.emit(e,t)}}class Ie{constructor(e){let t;if(t="string"===typeof e||"object"===typeof e&&e.constructor===String?JSON.parse(e):e||{},t.endpoint&&(t.url=t.endpoint,delete t.endpoint),t.log){if(!a([t.log.info,t.log.warn,t.log.error,t.log.debug,t.log.json],l))throw new Error("expected log object to have error, debug, info, warn and json methods");this.log=t.log}else this.log={info:e=>{console.info(`[${(new Date).toISOString()}] INFO: ${e}`)},debug:e=>{console.debug(`[${(new Date).toISOString()}] DEBUG: ${e}`)},warn:e=>{console.warn(`[${(new Date).toISOString()}] WARN: ${e}`)},error:e=>{console.error(`[${(new Date).toISOString()}] ERROR: ${e}`)},json:e=>{console.log(JSON.stringify(e))}};this.stopped=!0,this.uploadState$=new S(!1),this.analyseState$=new S(!1),this.reportState$=new S(!1),this.instanceTelemetry$=new S(null),this.experimentalWorkerStatus$=new S(null),this.runningStates$=$(this.uploadState$,this.analyseState$,this.reportState$),this.states={upload:{filesCount:0,success:{files:0,bytes:0,reads:0},types:{},niceTypes:"",progress:{bytes:0,total:0}},download:{progress:{},success:{files:0,reads:0,bytes:0},fail:0,types:{},niceTypes:""},warnings:[]},this.liveStates$=new S(this.states),this.config={options:c(t,pe),instance:{id_workflow_instance:t.id_workflow_instance,inputQueueName:null,outputQueueName:null,outputQueueURL:null,discoverQueueCache:{},bucket:null,bucketFolder:null,remote_addr:null,chain:null,key_id:null}},this.config.instance.awssettings={region:this.config.options.region},this.REST=new $e(s({log:this.log},this.config.options)),this.graphQL=new ke(s({log:this.log},this.config.options)),this.timers={downloadCheckInterval:null,stateCheckInterval:null,fileCheckInterval:null,transferTimeouts:{},visibilityIntervals:{},summaryTelemetryInterval:null}}async socket(){if(this.mySocket)return this.mySocket;this.mySocket=new be(this.REST,s({log:this.log},this.config.options));const{id_workflow_instance:e}=this.config.instance;return e&&this.mySocket.watch(`workflow_instance:state:${e}`,e=>{const{instance:t}=this.config;if(t){const{summaryTelemetry:s}=t,i=Object.entries(t.chain.components).sort((e,t)=>e[0]-t[0]).reduce((t,i)=>{const[o,r]=i;if(!e[o])return t;const n=+o,a=n&&Object.keys(s[r.wid])[0]||"ROOT",[l,c,h]=e[o].split(",").map(e=>Math.max(0,+e));return[...t,{running:l,complete:c,error:h,step:n,name:a}]},[]);this.experimentalWorkerStatus$.next(i)}}),this.mySocket}async realtimeFeedback(e,t){(await this.socket()).emit(e,t)}stopTimer(e){this.timers[e]&&(this.log.debug(`clearing ${e} interval`),clearInterval(this.timers[e]),this.timers[e]=null)}async stopAnalysis(){this.stopUpload(),this.stopped=!0;const{id_workflow_instance:e}=this.config.instance;if(e){try{this.config.options.graphQL?await this.graphQL.stopWorkflow({variables:{idWorkflowInstance:e}}):await this.REST.stopWorkflow(e),this.analyseState$.next(!1)}catch(t){return this.log.error(`Error stopping instance: ${String(t)}`),Promise.reject(t)}this.log.info(`workflow instance ${e} stopped`)}return Promise.resolve()}async stopUpload(){this.log.debug("stopping watchers"),["stateCheckInterval","fileCheckInterval"].forEach(e=>this.stopTimer(e)),this.uploadState$.next(!1)}async stopEverything(){this.stopAnalysis(),Object.keys(this.timers.transferTimeouts).forEach(e=>{this.log.debug(`clearing transferTimeout for ${e}`),clearTimeout(this.timers.transferTimeouts[e]),delete this.timers.transferTimeouts[e]}),Object.keys(this.timers.visibilityIntervals).forEach(e=>{this.log.debug(`clearing visibilityInterval for ${e}`),clearInterval(this.timers.visibilityIntervals[e]),delete this.timers.visibilityIntervals[e]}),this.downloadWorkerPool&&(this.log.debug("clearing downloadWorkerPool"),await Promise.all(Object.values(this.downloadWorkerPool)),this.downloadWorkerPool=null),["summaryTelemetryInterval","downloadCheckInterval"].forEach(e=>this.stopTimer(e))}reportProgress(){const{upload:e,download:t}=this.states;this.log.json({progress:{download:t,upload:e}})}storeState(e,t,s,i){const o=i||{};this.states[e]||(this.states[e]={}),this.states[e][t]||(this.states[e][t]={}),"incr"===s?Object.keys(o).forEach(s=>{this.states[e][t][s]=this.states[e][t][s]?this.states[e][t][s]+parseInt(o[s],10):parseInt(o[s],10)}):Object.keys(o).forEach(s=>{this.states[e][t][s]=this.states[e][t][s]?this.states[e][t][s]-parseInt(o[s],10):-parseInt(o[s],10)});try{this.states[e].success.niceReads=ve(this.states[e].success.reads)}catch(n){this.states[e].success.niceReads=0}try{this.states[e].progress.niceSize=ve(this.states[e].success.bytes+this.states[e].progress.bytes||0)}catch(n){this.states[e].progress.niceSize=0}try{this.states[e].success.niceSize=ve(this.states[e].success.bytes)}catch(n){this.states[e].success.niceSize=0}this.states[e].niceTypes=Object.keys(this.states[e].types||{}).sort().map(t=>`${this.states[e].types[t]} ${t}`).join(", ");const r=Date.now();(!this.stateReportTime||r-this.stateReportTime>2e3)&&(this.stateReportTime=r,this.reportProgress()),this.liveStates$.next(Object.assign({},this.states))}uploadState(e,t,s){return this.storeState("upload",e,t,s)}downloadState(e,t,s){return this.storeState("download",e,t,s)}url(){return this.config.options.url}apikey(){return this.config.options.apikey}attr(e,t){if(!(e in this.config.options))throw new Error(`config object does not contain property ${e}`);return t?(this.config.options[e]=t,this):this.config.options[e]}stats(e){return this.states[e]}}Ie.version=le.version,Ie.Profile=Se,Ie.REST=$e,Ie.utils=le;const _e={fastq:function(e){return new Promise((s,i)=>{let o=1,r=-1,n={size:0};try{n=t.statSync(e)}catch(a){return void i(a)}t.createReadStream(e).on("data",e=>{r=-1,o-=1;do{r=e.indexOf(10,r+1),o+=1}while(-1!==r)}).on("end",()=>s({type:"fastq",bytes:n.size,reads:Math.floor(o/4)})).on("error",i)})},fasta:function(e){return new Promise((s,i)=>{let o=1,r=-1,n={size:0};try{n=t.statSync(e)}catch(a){i(a)}t.createReadStream(e).on("data",e=>{r=-1,o-=1;do{r=e.indexOf(62,r+1),o+=1}while(-1!==r)}).on("end",()=>s({type:"fasta",bytes:n.size,sequences:Math.floor((1+o)/2)})).on("error",i)})},fastqgz:function(e){return new Promise((s,i)=>{let o=1,r=-1,n={size:0};try{n=t.statSync(e)}catch(l){return void i(l)}const a=R();t.createReadStream(e).pipe(a).on("data",e=>{r=-1,o-=1;do{r=e.indexOf(10,r+1),o+=1}while(-1!==r)}).on("end",()=>s({type:"gz",bytes:n.size,reads:Math.floor(o/4)})).on("error",i)})},default:async function(e){return t.stat(e).then(e=>({type:"bytes",bytes:e.size}))}},Ee={fq:"fastq",fa:"fasta"};function Pe(e){if("string"!==typeof e&&!(e instanceof String))return Promise.resolve({});let t=g.extname(e).toLowerCase().replace(/^[.]/,"");if(Ee[t]&&(t=Ee[t]),"gz"===t){t=e.split(".").slice(1).reduce((e,t)=>e+(Ee[t]||t),"")}return _e[t]||(t="default"),_e[t](e)}class Te extends Se{constructor(e,i){super({}),this.raiseExceptions=!!i,this.prefsFile=e||Te.profilePath(),this.allProfileData={};try{this.allProfileData=s({profiles:{}},t.readJSONSync(this.prefsFile)),this.allProfileData.endpoint&&(this.defaultEndpoint=this.allProfileData.endpoint)}catch(o){if(this.raiseExceptions)throw o}}static profilePath(){return g.join(d(),".epi2me.json")}profile(e,i){if(e&&i){s(this.allProfileData,{profiles:{[e]:i}});try{t.writeJSONSync(this.prefsFile,this.allProfileData)}catch(o){if(this.raiseExceptions)throw o}}if(e){if(!this.allProfileData.profiles)throw new Error("cannot read property");return s({endpoint:this.defaultEndpoint},this.allProfileData.profiles[e])}return{}}}class je{static MakeQueryablePromise(e){if(e.isResolved)return e;let t=!0,s=!1,i=!1;const o=e.then(e=>(i=!0,t=!1,e)).catch(e=>{throw s=!0,t=!1,e});return o.dependsOn=e,o.isResolved=()=>i,o.isPending=()=>t,o.isRejected=()=>s,o}constructor(e){const t=s({bandwidth:1,interval:500},e);this.bandwidth=t.bandwidth,this.interval=t.interval,this.pipeline=[],this.running=[],this.completed=0,this.intervalId=null,"start"in t&&!t.start||this.start()}enqueue(e){this.pipeline.push(e)}start(){this.intervalId||(this.intervalId=setInterval(()=>{this.monitorInterval()},this.interval))}stop(){clearInterval(this.intervalId),delete this.intervalId}state(){return{queued:this.pipeline.length,running:this.running.length,completed:this.completed,state:this.intervalId?"running":"stopped"}}monitorInterval(){this.running.map((e,t)=>e.isPending()?null:t).filter(e=>e).reverse().forEach(e=>{this.running.splice(e,1),this.completed+=1});const e=this.bandwidth-this.running.length;for(let t=0;t<e;t+=1){const e=this.pipeline.shift();if(!e)return;this.running.push(je.MakeQueryablePromise(e()))}}}class xe extends $e{async workflows(e){if(!this.options.local)return super.workflows(e);const s=g.join(this.options.url,"workflows");let i;try{return i=(await t.readdir(s)).filter(e=>t.statSync(g.join(s,e)).isDirectory()).map(e=>g.join(s,e,"workflow.json")).map(e=>t.readJsonSync(e)),e?e(null,i):Promise.resolve(i)}catch(o){return this.log.warn(o),e?e(void 0):Promise.reject(void 0)}}async workflow(e,s,i){if(!this.options.local||!e||"object"===typeof e||i)return super.workflow(e,s,i);const o=g.join(this.options.url,"workflows"),r=g.join(o,e,"workflow.json");try{const e=await t.readJson(r);return i?i(null,e):Promise.resolve(e)}catch(n){return i?i(n):Promise.reject(n)}}async workflowInstances(e,s){if(!this.options.local)return super.workflowInstances(e,s);let i,o;if(!e||e instanceof Function||void 0!==s?(i=e,o=s):o=e,o){const e=new Error("querying of local instances unsupported in local mode");return i?i(e):Promise.reject(e)}const r=g.join(this.options.url,"instances");try{let e=await t.readdir(r);return e=e.filter(e=>t.statSync(g.join(r,e)).isDirectory()),e=e.map(e=>{const s=g.join(r,e,"workflow.json");let i;try{i=t.readJsonSync(s)}catch(o){i={id_workflow:"-",description:"-",rev:"0.0"}}return i.id_workflow_instance=e,i.filename=s,i}),i?i(null,e):Promise.resolve(e)}catch(n){return i?i(n):Promise.reject(n)}}async datasets(e,s){if(!this.options.local)return super.datasets(e,s);let i,o;if(!e||e instanceof Function||void 0!==s?(i=e,o=s):o=e,o||(o={}),o.show||(o.show="mine"),"mine"!==o.show)return i(new Error("querying of local datasets unsupported in local mode"));const r=g.join(this.options.url,"datasets");try{let e=await t.readdir(r);e=e.filter(e=>t.statSync(g.join(r,e)).isDirectory());let s=0;return e=e.sort().map(e=>(s+=1,{is_reference_dataset:!0,summary:null,dataset_status:{status_label:"Active",status_value:"active"},size:0,prefix:e,id_workflow_instance:null,id_account:null,is_consented_human:null,data_fields:null,component_id:null,uuid:e,is_shared:!1,id_dataset:s,id_user:null,last_modified:null,created:null,name:e,source:e,attributes:null})),i?i(null,e):Promise.resolve(e)}catch(n){return this.log.warn(n),i?i(null,[]):Promise.resolve([])}}async bundleWorkflow(e,t,s){return le.pipe(`workflow/bundle/${e}.tar.gz`,t,this.options,s)}}class Oe{constructor(){this.experiments={}}async getExperiments({sourceDir:e=pe.sampleDirectory,refresh:t=!1}){return Object.keys(this.experiments).length&&!t||await this.updateExperiments(e),this.experiments}async updateExperiments(e=pe.sampleDirectory){const t=(new N).withBasePath().withErrors().filter(e=>e.includes("sequencing_summary")).exclude(e=>e.includes("fastq_")).withMaxDepth(3).crawl(e);let s;try{s=await t.withPromise()}catch(i){return}this.experiments=s.reduce((e,t)=>{var s;const[i,o]=h(t.split(g.sep),3),r=/(?<date>[0-9]{8})_(?<time>[0-9]{4})_.*_(?<flowcell>\w+\d+)_\w+/;if(!r.test(o))return e;const{date:n,time:a,flowcell:l}=null===(s=r.exec(o))||void 0===s?void 0:s.groups,c=`${n.slice(0,4)}-${n.slice(4,6)}-${n.slice(6,8)}`,u=`T${a.slice(0,2)}:${a.slice(2,4)}:00`,p=new Date(c+u);return e[i]={startDate:`${p.toDateString()} ${p.toLocaleTimeString()}`,samples:[...e[i]?e[i].samples:[],{sample:o,flowcell:l,path:`${g.dirname(t)}/fastq_pass`}]},e},{})}}class Re{constructor(e,t,i,o,r){if(this.id_workflow_instance=e,this.children=i,this.options=s(o),this.log=this.options.log,this.REST=t,this.graphQL=r,!e)throw new Error("must specify id_workflow_instance");if(!i||!i.length)throw new Error("must specify children to session")}async session(){if(this.sts_expiration&&this.sts_expiration>Date.now())return Promise.resolve();this.log.debug("new instance token needed");try{const e=this.options.useGraphQL?(await this.graphQL.instanceToken({variables:{idWorkflowInstance:this.id_workflow_instance}})).data.token:await this.REST.instanceToken(this.id_workflow_instance,this.options);this.log.debug(`allocated new instance token expiring at ${e.expiration}`),this.sts_expiration=new Date(e.expiration).getTime()-60*parseInt(this.options.sessionGrace||"0",10);const t={};this.options.proxy&&s(t,{httpOptions:{agent:C(this.options.proxy,!0)}}),s(t,{region:this.options.region},e),this.children.forEach(e=>{try{e.config.update(t)}catch(s){this.log.warn(`failed to update config on ${String(e)}: ${String(s)}`)}})}catch(e){this.log.warn(`failed to fetch instance token: ${String(e)}`)}return Promise.resolve()}}async function Ne(e,i,o,r,n,a){const{maxChunkBytes:l,maxChunkReads:c}=s(i),h=g.dirname(e),u=g.basename(e),p=u.match(/^[^.]+/),d=p?p[0]:"",f=u.replace(d,""),m=g.join(h,d);if(!l&&!c)return o(e).then(()=>({source:e,split:!1,chunks:[e]}));const w=await t.stat(e);return l&&w.size<l?o(e).then(()=>({source:e,split:!1,chunks:[e]})):new Promise(i=>{let h,u,p=0,d=0,g="",w=0,y=0;const k={source:e,split:!0,chunks:[]};let v;const S=[new Promise(e=>{v=e})];A.createInterface({input:n(e)}).on("line",async e=>{d+=1,g+=e,g+="\n",d>=4&&(d=0,(async e=>{if(!w){p+=1,h=`${m}_${p}${f}`;const e=new Promise((e,s)=>{const i=h,n=()=>{o(i).then(()=>{e(i)}).catch(e=>{s(e)}).finally(()=>{t.unlink(i).catch(e=>{r.warn(`Error unlinking chunk ${i}: ${String(e)}`)})})};a?u=a(i,n):(u=t.createWriteStream(i),u.on("close",n))});S.push(e)}w+=1,y+=e.length,u.write(e,()=>{}),(l&&y>=l||c&&w>=c)&&(w=0,y=0,u.end())})(g),g="")}).on("close",()=>{u.end(),v(),Promise.all(S).then(e=>{e.shift(),i(s({chunks:e},k))})}).on("error",t=>{r.error(`Error chunking ${e}: ${String(t)}`)})})}async function Ce(e,s,i,o){return Ne(e,s,i,o,e=>t.createReadStream(e))}async function Ae(e,s,i,o){return Ne(e,s,i,o,e=>t.createReadStream(e).pipe(O.createGunzip()),(e,s)=>{const i=t.createWriteStream(e);i.on("close",s);const o=O.createGzip();return o.pipe(i),o})}const Me=()=>{const e=process.env.APPDATA||("darwin"===process.platform?g.join(d(),"Library/Application Support"):d());return process.env.EPI2ME_HOME||g.join(e,"linux"===process.platform?".epi2me":"EPI2ME")};class Fe extends Ie{constructor(e){super(e),this.config.options.inputFolders=this.config.options.inputFolders||[],this.config.options.inputFolder&&this.config.options.inputFolders.push(this.config.options.inputFolder),this.REST=new xe(s({},{log:this.log},this.config.options)),this.SampleReader=new Oe,this.uploadsInProgress=[]}async sessionedS3(){return this.sessionManager||(this.sessionManager=this.initSessionManager()),await this.sessionManager.session(),new e.S3({useAccelerateEndpoint:"on"===this.config.options.awsAcceleration})}async sessionedSQS(){return this.sessionManager||(this.sessionManager=this.initSessionManager()),await this.sessionManager.session(),new e.SQS}async deleteMessage(e){try{const t=await this.discoverQueue(this.config.instance.outputQueueName);return(await this.sessionedSQS()).deleteMessage({QueueUrl:t,ReceiptHandle:e.ReceiptHandle}).promise()}catch(t){return this.log.error(`deleteMessage exception: ${String(t)}`),this.states.download.failure||(this.states.download.failure={}),this.states.download.failure[t]=this.states.download.failure[t]?this.states.download.failure[t]+1:1,Promise.reject(t)}}async discoverQueue(e){if(this.config.instance.discoverQueueCache[e])return Promise.resolve(this.config.instance.discoverQueueCache[e]);let t;this.log.debug(`discovering queue for ${e}`);try{const s=await this.sessionedSQS();t=await s.getQueueUrl({QueueName:e}).promise()}catch(s){return this.log.error(`Error: failed to find queue for ${e}: ${String(s)}`),Promise.reject(s)}return this.log.debug(`found queue ${t.QueueUrl}`),this.config.instance.discoverQueueCache[e]=t.QueueUrl,Promise.resolve(t.QueueUrl)}async queueLength(e){if(!e)return Promise.reject(new Error("no queueURL specified"));const t=e.match(/([\w\-_]+)$/)[0];this.log.debug(`querying queue length of ${t}`);try{const t=await this.sessionedSQS(),s=await t.getQueueAttributes({QueueUrl:e,AttributeNames:["ApproximateNumberOfMessages"]}).promise();if((null===s||void 0===s?void 0:s.Attributes)&&"ApproximateNumberOfMessages"in s.Attributes){let e=s.Attributes.ApproximateNumberOfMessages;return e=parseInt(e,10)||0,Promise.resolve(e)}return Promise.reject(new Error("unexpected response"))}catch(s){return this.log.error(`error in getQueueAttributes ${String(s)}`),Promise.reject(s)}}async autoStart(e,t){const s=await this.autoStartGeneric(e,()=>this.REST.startWorkflow(e),t);return this.setClassConfigREST(s),this.autoConfigure(s,t)}async autoStartGQL(e,t){const s=await this.autoStartGeneric(e,()=>this.graphQL.startWorkflow({variables:e}),t);return this.setClassConfigGQL(s),this.autoConfigure(this.config.instance,t)}async autoStartGeneric(e,t,s){let i;this.stopped=!1;try{i=await t(),this.analyseState$.next(!0)}catch(o){const e=`Failed to start workflow: ${String(o)}`;return this.log.warn(e),s?s(e):Promise.reject(o)}return this.config.workflow=JSON.parse(JSON.stringify(e)),this.log.info(`instance ${JSON.stringify(i)}`),this.log.info(`workflow config ${JSON.stringify(this.config.workflow)}`),i}async autoJoin(e,t){let s;this.stopped=!1,this.config.instance.id_workflow_instance=e;try{s=await this.REST.workflowInstance(e)}catch(i){const e=`Failed to join workflow instance: ${String(i)}`;return this.log.warn(e),t?t(e):Promise.reject(i)}return"stopped"===s.state?(this.log.warn(`workflow ${e} is already stopped`),t?t("could not join workflow"):Promise.reject(new Error("could not join workflow"))):(this.config.workflow=this.config.workflow||{},this.log.debug(`instance ${JSON.stringify(s)}`),this.log.debug(`workflow config ${JSON.stringify(this.config.workflow)}`),this.setClassConfigREST(s),this.autoConfigure(s,t))}setClassConfigGQL({data:{startData:{bucket:e,idUser:t,remoteAddr:s,userDefined:i={},instance:{outputqueue:o,keyId:r,startDate:n,idWorkflowInstance:a,mappedTelemetry:l,chain:c,workflowImage:{region:{name:h},workflow:{idWorkflow:u},inputqueue:p}}}}}){const d={bucket:e,user_defined:i,id_user:parseInt(t),remote_addr:s,id_workflow_instance:a,key_id:r,start_date:n,outputQueueName:o,summaryTelemetry:l,inputQueueName:p,id_workflow:parseInt(u),region:h||this.config.options.region,bucketFolder:`${o}/${t}/${a}`,chain:le.convertResponseToObject(c)};this.config.instance=Object.assign(Object.assign({},this.config.instance),d)}setClassConfigREST(e){["id_workflow_instance","id_workflow","remote_addr","key_id","bucket","user_defined","start_date","id_user"].forEach(t=>{this.config.instance[t]=e[t]}),this.config.instance.inputQueueName=e.inputqueue,this.config.instance.outputQueueName=e.outputqueue,this.config.instance.region=e.region||this.config.options.region,this.config.instance.bucketFolder=`${e.outputqueue}/${e.id_user}/${e.id_workflow_instance}`,this.config.instance.summaryTelemetry=e.telemetry,e.chain&&(this.config.instance.chain=le.convertResponseToObject(e.chain))}initSessionManager(t,i){return new Re(this.config.instance.id_workflow_instance,this.REST,[e,...i||[]],s({sessionGrace:this.config.options.sessionGrace,proxy:this.config.options.proxy,region:this.config.instance.region,log:this.log,useGraphQL:this.config.options.useGraphQL},t),this.graphQL)}async autoConfigure(e,s){if(!this.config.options.inputFolders.length)throw new Error("must set inputFolder");if(!this.config.options.outputFolder)throw new Error("must set outputFolder");if(!this.config.instance.bucketFolder)throw new Error("bucketFolder must be set");if(!this.config.instance.inputQueueName)throw new Error("inputQueueName must be set");if(!this.config.instance.outputQueueName)throw new Error("outputQueueName must be set");t.mkdirpSync(this.config.options.outputFolder);const i=g.join(Me(),"instances"),o=g.join(i,this.config.instance.id_workflow_instance);this.db=new he(o,{idWorkflowInstance:this.config.instance.id_workflow_instance,inputFolders:this.config.options.inputFolders},this.log);const r=this.config.instance.id_workflow_instance?`telemetry-${this.config.instance.id_workflow_instance}.log`:"telemetry.log",n=g.join(this.config.options.outputFolder,"epi2me-logs"),a=g.join(n,r);return t.mkdirp(n,e=>{if(e&&!String(e).match(/EEXIST/))this.log.error(`error opening telemetry log stream: mkdirpException:${String(e)}`);else try{this.telemetryLogStream=t.createWriteStream(a,{flags:"a"}),this.log.info(`logging telemetry to ${a}`)}catch(s){this.log.error(`error opening telemetry log stream: ${String(s)}`)}}),s&&s(null,this.config.instance),this.timers.summaryTelemetryInterval=setInterval(()=>{this.stopped?clearInterval(this.timers.summaryTelemetryInterval):this.fetchTelemetry()},1e4*this.config.options.downloadCheckInterval),this.timers.downloadCheckInterval=setInterval(()=>{this.stopped?clearInterval(this.timers.downloadCheckInterval):this.checkForDownloads()},1e3*this.config.options.downloadCheckInterval),this.timers.stateCheckInterval=setInterval(async()=>{if(this.stopped)clearInterval(this.timers.stateCheckInterval);else try{let t;if(this.config.options.useGraphQL?({data:{instanceObj:t}}=await this.graphQL.query("query workflowInstance($idWorkflowInstance: ID!) {\n              instanceObj:workflowInstance(idWorkflowInstance: $idWorkflowInstance) {\n                stop_date: stopDate\n                state\n              }\n            }")({variables:{idWorkflowInstance:this.config.instance.id_workflow_instance}})):t=await this.REST.workflowInstance(this.config.instance.id_workflow_instance),"stopped"===t.state){this.log.warn(`instance was stopped remotely at ${t.stop_date}. shutting down the workflow.`);try{const e=await this.stopEverything();"function"===typeof e.config.options.remoteShutdownCb&&e.config.options.remoteShutdownCb(`instance was stopped remotely at ${t.stop_date}`)}catch(e){this.log.error(`Error whilst stopping: ${String(e)}`)}}}catch(t){this.log.warn(`failed to check instance state: ${(null===t||void 0===t?void 0:t.error)?t.error:t}`)}},1e3*this.config.options.stateCheckInterval),this.sessionManager=this.initSessionManager(),await this.sessionManager.session(),this.reportProgress(),this.loadUploadFiles(),this.uploadState$.next(!0),this.timers.fileCheckInterval=setInterval(this.loadUploadFiles.bind(this),1e3*this.config.options.fileCheckInterval),Promise.resolve(e)}async stopUpload(){for(const e of this.uploadsInProgress)e.abort();if(this.uploadsInProgress=[],await super.stopUpload(),this.log.debug("clearing split files"),this.db)return this.db.splitClean()}async stopEverything(){delete this.sessionManager,await super.stopEverything()}async checkForDownloads(){if(this.checkForDownloadsRunning)return Promise.resolve();this.checkForDownloadsRunning=!0,this.log.debug("checkForDownloads checking for downloads");try{const e=await this.discoverQueue(this.config.instance.outputQueueName),t=await this.queueLength(e);t?(this.log.debug(`downloads available: ${t}`),await this.downloadAvailable()):this.log.debug("no downloads available")}catch(e){this.log.warn(`checkForDownloads error ${String(e)}`),this.states.download.failure||(this.states.download.failure={}),this.states.download.failure[e]=this.states.download.failure[e]?this.states.download.failure[e]+1:1}return this.checkForDownloadsRunning=!1,Promise.resolve()}async downloadAvailable(){const e=Object.keys(this.downloadWorkerPool||{}).length;if(e>=this.config.options.transferPoolSize)return this.log.debug(`${e} downloads already queued`),Promise.resolve();let t;try{const s=await this.discoverQueue(this.config.instance.outputQueueName);this.log.debug("fetching messages");const i=await this.sessionedSQS();t=await i.receiveMessage({AttributeNames:["All"],QueueUrl:s,VisibilityTimeout:this.config.options.inFlightDelay,MaxNumberOfMessages:this.config.options.transferPoolSize-e,WaitTimeSeconds:this.config.options.waitTimeSeconds}).promise()}catch(s){return this.log.error(`receiveMessage exception: ${String(s)}`),this.states.download.failure[s]=this.states.download.failure[s]?this.states.download.failure[s]+1:1,Promise.reject(s)}return this.receiveMessages(t)}async loadUploadFiles(){if(this.dirScanInProgress)return Promise.resolve();this.dirScanInProgress=!0,this.log.debug("upload: started directory scan");try{const e=e=>this.db.seenUpload(e),t=await le.loadInputFiles(this.config.options,this.log,e);let s=0;const i=()=>new Promise(e=>{if(this.stopped)return t.length=0,this.log.debug("upload: skipping, stopped"),void e();if(s>this.config.options.transferPoolSize)return void setTimeout(e,1e3);const i=t.splice(0,this.config.options.transferPoolSize-s);s+=i.length,this.enqueueUploadFiles(i).then().catch(e=>{this.log.error(`upload: exception in enqueueUploadFiles: ${String(e)}`)}).finally(()=>{s-=i.length,e()})});for(;t.length;)await i()}catch(e){this.log.error(`upload: exception in loadInputFiles: ${String(e)}`)}return this.dirScanInProgress=!1,this.log.debug("upload: finished directory scan"),Promise.resolve()}async enqueueUploadFiles(e){let t=0,s=0,i=0,o=0,r={};if(!u(e)||!e.length)return Promise.resolve();if(this.log.info(`enqueueUploadFiles ${e.length} files: ${e.map(e=>e.path).join(" ")}.`),"workflow"in this.config)if("workflow_attributes"in this.config.workflow)r=this.config.workflow.workflow_attributes;else if("attributes"in this.config.workflow){let{attributes:e}=this.config.workflow;if(e||(e={}),["max_size","max_files","split_size","split_reads"].forEach(t=>{`epi2me:${t}`in e&&(r[t]=parseInt(e[`epi2me:${t}`],10))}),"epi2me:category"in e){e["epi2me:category"].includes("storage")&&(r.requires_storage=!0)}}if(this.log.info(`enqueueUploadFiles settings ${JSON.stringify(r)}`),"requires_storage"in r&&r.requires_storage&&!("storage_account"in this.config.workflow)){const e={msg:"ERROR: Workflow requires storage enabled. Please provide a valid storage account [ --storage ].",type:"WARNING_STORAGE_ENABLED"};return this.log.error(e.msg),this.states.warnings.push(e),Promise.resolve()}if("split_size"in r&&(i=parseInt(r.split_size,10),this.log.info(`enqueueUploadFiles splitting supported files at ${i} bytes`)),"split_reads"in r&&(o=parseInt(r.split_reads,10),this.log.info(`enqueueUploadFiles splitting supported files at ${o} reads`)),"max_size"in r&&(s=parseInt(r.max_size,10),this.log.info(`enqueueUploadFiles restricting file size to ${s}`)),"max_files"in r&&(t=parseInt(r.max_files,10),this.log.info(`enqueueUploadFiles restricting file count to ${t}`),e.length>t)){const s={msg:`ERROR: ${e.length} files found. Workflow can only accept ${t}. Please move the extra files away.`,type:"WARNING_FILE_TOO_MANY"};return this.log.error(s.msg),this.states.warnings.push(s),Promise.resolve()}this.states.upload.filesCount+=e.length;const n=e.map(async e=>{var r;const n=e;if(t&&this.states.upload.filesCount>t){const e=`Maximum ${t} file(s) already uploaded. Marking ${n.relative} as skipped.`,s={msg:e,type:"WARNING_FILE_TOO_MANY"};this.log.error(e),this.states.warnings.push(s),this.states.upload.filesCount-=1,n.skip="SKIP_TOO_MANY"}else if(0===n.size){const e=`The file "${n.relative}" is empty. It will be skipped.`,t={msg:e,type:"WARNING_FILE_EMPTY"};n.skip="SKIP_EMPTY",this.states.upload.filesCount-=1,this.log.error(e),this.states.warnings.push(t)}else{if((null===(r=n.path)||void 0===r?void 0:r.match(/\.(?:fastq|fq)(?:\.gz)?$/))&&(i&&n.size>i||o)){const e=`${n.relative}${n.size>i?" is too big and":""} is going to be split`;this.log.warn(e);const t={msg:e,type:"WARNING_FILE_SPLIT"};this.states.warnings.push(t);const s=i?{maxChunkBytes:i}:{maxChunkReads:o},r=n.path.match(/\.gz$/)?Ae:Ce,l=le.getFileID(),c=new je({bandwidth:this.config.options.transferPoolSize});let h=0;const u=async e=>(this.log.debug(`chunkHandler for ${e}`),await this.db.splitFile(e,n.path),this.stopped?(c.stop(),this.log.info(`stopped, so skipping ${e}`),Promise.reject(new Error("stopped"))):(h+=1,Pe(e).then(t=>({name:g.basename(e),path:e,relative:e.replace(this.config.options.inputFolder,""),id:`${l}_${h}`,stats:t,size:t.bytes})).then(async e=>{const t=new Promise(t=>{c.enqueue(()=>(this.log.info(`chunk upload starting ${e.id} ${e.path}`),this.stopped?(this.log.info(`chunk upload skipped (stopped) ${e.id} ${e.path}`),c.stop(),t(),Promise.resolve()):this.uploadJob(e).then(()=>this.db.splitDone(e.path)).catch(t=>{this.log.error(`chunk upload failed ${e.id} ${e.path}: ${String(t)}`)}).finally(t)))});await t})));try{await r(n.path,s,u,this.log),c.stop()}catch(a){if(c.stop(),"Error: stopped"===String(a))return Promise.resolve();throw a}return this.db.uploadFile(n.path)}if(s&&n.size>s){const e=`The file "${n.relative}" is bigger than the maximum size limit (${ve(s)}B). It will be skipped.`,t={msg:e,type:"WARNING_FILE_TOO_BIG"};n.skip="SKIP_TOO_BIG",this.states.upload.filesCount-=1,this.log.error(e),this.states.warnings.push(t)}else try{n.stats=await Pe(n.path)}catch(l){this.log.error(`failed to stat ${n.path}: ${String(l)}`)}}return this.uploadJob(n)});try{return await Promise.all(n),this.log.info(`upload: inputBatchQueue (${n.length} jobs) complete`),this.loadUploadFiles()}catch(a){return this.log.error(`upload: enqueueUploadFiles exception ${String(a)}`),Promise.reject(a)}}async uploadJob(e){if("skip"in e)return this.db.skipFile(e.path);let t,i;try{this.log.info(`upload: ${e.id} starting`),t=await this.uploadHandler(e),this.log.info(`upload: ${t.id} uploaded and notified`)}catch(o){i=o,this.log.error(`upload: ${e.id} done, but failed: ${String(i)}`)}if(t||(t={}),i){if(this.log.error(`uploadJob ${i}`),this.states.upload.failure||(this.states.upload.failure={}),this.states.upload.failure[i]=this.states.upload.failure[i]?this.states.upload.failure[i]+1:1,String(i).match(/AWS.SimpleQueueService.NonExistentQueue/))return this.log.error("instance stopped because of a fatal error"),this.stopEverything()}else if(this.uploadState("success","incr",s({files:1},t.stats)),t.name){const e=g.extname(t.name);this.uploadState("types","incr",{[e]:1})}return Promise.resolve()}async receiveMessages(e){return e&&e.Messages&&e.Messages.length?(this.downloadWorkerPool||(this.downloadWorkerPool={}),e.Messages.forEach(e=>{this.downloadWorkerPool[e.MessageId]=1;const t=setTimeout(()=>{throw this.log.error(`this.downloadWorkerPool timeoutHandle. Clearing queue slot for message: ${e.MessageId}`),new Error("download timed out")},1e3*(60+this.config.options.downloadTimeout));this.processMessage(e).catch(e=>{this.log.error(`processMessage ${String(e)}`)}).finally(()=>{clearTimeout(t),e&&delete this.downloadWorkerPool[e.MessageId]})}),this.log.info(`downloader queued ${e.Messages.length} messages for processing`),Promise.resolve()):(this.log.info("complete (empty)"),Promise.resolve())}async processMessage(e){var i,o,r,n,a,l,c;let h,u;if(!e)return this.log.debug("download.processMessage: empty message"),Promise.resolve();"Attributes"in e&&"ApproximateReceiveCount"in e.Attributes&&this.log.debug(`download.processMessage: ${e.MessageId} / ${e.Attributes.ApproximateReceiveCount}`);try{h=JSON.parse(e.Body)}catch(w){this.log.error(`error parsing JSON message.Body from message: ${JSON.stringify(e)} ${String(w)}`);try{await this.deleteMessage(e)}catch(y){this.log.error(`Exception deleting message: ${String(y)}`)}return Promise.resolve()}if(h.telemetry){const{telemetry:t}=h;if(t.tm_path)try{this.log.debug(`download.processMessage: ${e.MessageId} fetching telemetry`);const s=await this.sessionedS3(),i=await s.getObject({Bucket:h.bucket,Key:t.tm_path}).promise();this.log.info(`download.processMessage: ${e.MessageId} fetched telemetry`),t.batch=i.Body.toString("utf-8").split("\n").filter(e=>(null===e||void 0===e?void 0:e.length)>0).map(e=>{try{return JSON.parse(e)}catch(y){return this.log.error(`Telemetry Batch JSON Parse error: ${String(y)}`),e}})}catch(k){this.log.error(`Could not fetch telemetry JSON: ${String(k)}`)}try{this.telemetryLogStream.write(JSON.stringify(t)+f)}catch(v){this.log.error(`error writing telemetry: ${v}`)}this.config.options.telemetryCb&&this.config.options.telemetryCb(t)}if(!h.path)return this.log.warn("nothing to download"),Promise.resolve();const p=h.path.match(/[\w\W]*\/([\w\W]*?)$/),d=p?p[1]:"";if(u=g.join(this.config.options.outputFolder,this.config.instance.id_workflow_instance||""),null===(o=null===(i=h.telemetry)||void 0===i?void 0:i.hints)||void 0===o?void 0:o.folder){this.log.debug(`using folder hint ${h.telemetry.hints.folder}`);const e=h.telemetry.hints.folder.split("/").map(e=>e.toUpperCase());u=g.join.apply(null,[u,...e])}t.mkdirpSync(u);const m=g.join(u,d);if("data+telemetry"===this.config.options.downloadMode){const t=[""];let s=(null===(a=null===(n=null===(r=this.config)||void 0===r?void 0:r.workflow)||void 0===n?void 0:n.settings)||void 0===a?void 0:a.output_format)?this.config.workflow.settings.output_format:[];("string"===typeof s||s instanceof String)&&(s=s.trim().split(/[\s,]+/));try{t.push(...s)}catch(y){this.log.error(`Failed to work out workflow file suffixes: ${String(y)}`)}try{const s=t.map(t=>{const s=h.path+t,i=m+t;return this.log.debug(`download.processMessage: ${e.MessageId} downloading ${s} to ${i}`),new Promise((o,r)=>{this.initiateDownloadStream({bucket:h.bucket,path:s},e,i).then(o).catch(e=>{this.log.error(`Caught exception waiting for initiateDownloadStream: ${String(e)}`),t?r(e):o()})})});await Promise.all(s)}catch(y){this.log.error(`Exception fetching file batch: ${String(y)}`)}try{const e=!(null===(l=h.telemetry)||void 0===l||!l.json)&&h.telemetry.json.exit_status;e&&this.config.options.dataCb&&this.config.options.dataCb(m,e)}catch(k){this.log.warn(`failed to fire data callback: ${k}`)}}else{const e=(null===(c=h.telemetry.batch_summary)||void 0===c?void 0:c.reads_num)?h.telemetry.batch_summary.reads_num:1;this.downloadState("success","incr",{files:1,reads:e})}try{await this.deleteMessage(e)}catch(y){this.log.error(`Exception deleting message: ${String(y)}`)}return this.realtimeFeedback("workflow_instance:state",{type:"stop",id_workflow_instance:this.config.instance.id_workflow_instance,id_workflow:this.config.instance.id_workflow,component_id:"0",message_id:s(e).MessageId,id_user:this.config.instance.id_user}).catch(e=>{this.log.warn(`realtimeFeedback failed: ${String(e)}`)}),Promise.resolve()}async initiateDownloadStream(e,i,o){return new Promise(async(r,n)=>{let a,l,c;try{a=await this.sessionedS3()}catch(p){n(p)}const h=s=>{if(this.log.error(`Error during stream of bucket=${e.bucket} path=${e.path} to file=${o} ${String(s)}`),clearTimeout(this.timers.transferTimeouts[o]),delete this.timers.transferTimeouts[o],!l.networkStreamError)try{l.networkStreamError=1,l.close(),t.remove(o).then(()=>{this.log.warn(`removed failed download ${o}`)}).catch(e=>{this.log.warn(`failed to remove ${o}. unlinkException: ${String(e)}`)}),c.destroy&&(this.log.error(`destroying read stream for ${o}`),c.destroy())}catch(p){this.log.error(`error handling stream error: ${String(p)}`)}};try{const s={Bucket:e.bucket,Key:e.path};l=t.createWriteStream(o);const i=a.getObject(s);i.on("httpHeaders",(e,t)=>{this.downloadState("progress","incr",{total:parseInt(t["content-length"],10)})}),c=i.createReadStream()}catch(d){return this.log.error(`getObject/createReadStream exception: ${String(d)}`),void n(d)}c.on("error",h),l.on("finish",async()=>{if(!l.networkStreamError){this.log.debug(`downloaded ${o}`);try{const e=g.extname(o),t=await Pe(o);this.downloadState("success","incr",s({files:1},t)),this.downloadState("types","incr",{[e]:1}),this.downloadState("progress","decr",{total:t.bytes,bytes:t.bytes})}catch(e){this.log.warn(`failed to stat ${o}: ${String(e)}`)}this.reportProgress()}}),l.on("close",t=>{this.log.debug(`closing writeStream ${o}`),t&&this.log.error(`error closing write stream ${t}`),clearInterval(this.timers.visibilityIntervals[o]),delete this.timers.visibilityIntervals[o],clearTimeout(this.timers.transferTimeouts[o]),delete this.timers.transferTimeouts[o],setTimeout(this.checkForDownloads.bind(this)),this.log.info(`download.initiateDownloadStream: ${i.MessageId} downloaded ${e.path} to ${o}`),r()}),l.on("error",h);const u=()=>{h(new Error("transfer timed out"))};this.timers.transferTimeouts[o]=setTimeout(u,1e3*this.config.options.downloadTimeout);this.timers.visibilityIntervals[o]=setInterval(async()=>{this.stopped&&(clearInterval(this.timers.visibilityIntervals[o]),delete this.timers.visibilityIntervals[o]);const e=this.config.instance.outputQueueURL,t=i.ReceiptHandle;this.log.debug({message_id:i.MessageId},"updateVisibility");try{await this.sqs.changeMessageVisibility({QueueUrl:e,ReceiptHandle:t,VisibilityTimeout:this.config.options.inFlightDelay}).promise()}catch(s){this.log.error({message_id:i.MessageId,queue:e,error:s},"Error setting visibility"),clearInterval(this.timers.visibilityIntervals[o])}},900*this.config.options.inFlightDelay),c.on("data",e=>{clearTimeout(this.timers.transferTimeouts[o]),this.timers.transferTimeouts[o]=setTimeout(u,1e3*this.config.options.downloadTimeout),this.downloadState("progress","incr",{bytes:e.length})}).pipe(l)})}async uploadHandler(e){const s=await this.sessionedS3();let i;const o=e.relative.replace(/^[\\/]+/,"").replace(/\\/g,"/").replace(/\//g,"_"),r=[this.config.instance.bucketFolder,"component-0",o,o].join("/").replace(/\/+/g,"/");let n;return new Promise((o,a)=>{const l=()=>{i&&!i.closed&&i.close(),a(new Error(`${e.name} timed out`))};n=setTimeout(l,1e3*(this.config.options.uploadTimeout+5));try{i=t.createReadStream(e.path)}catch(c){return clearTimeout(n),void a(c)}i.on("error",e=>{i.close();let t="error in upload readstream";(null===e||void 0===e?void 0:e.message)&&(t+=`: ${e.message}`),clearTimeout(n),a(new Error(t))}),i.on("open",()=>{const t={Bucket:this.config.instance.bucket,Key:r,Body:i};this.config.instance.key_id&&(t.SSEKMSKeyId=this.config.instance.key_id,t.ServerSideEncryption="aws:kms"),e.size&&(t["Content-Length"]=e.size),this.uploadState("progress","incr",{total:e.size});let c=0;const h=s.upload(t,{partSize:10485760,queueSize:1});this.uploadsInProgress.push(h);const u=this.initSessionManager(null,[h.service]);u.sts_expiration=this.sessionManager.sts_expiration,h.on("httpUploadProgress",async e=>{this.uploadState("progress","incr",{bytes:e.loaded-c}),c=e.loaded,clearTimeout(n),n=setTimeout(l,1e3*(this.config.options.uploadTimeout+5));try{await u.session()}catch(t){this.log.warn(`Error refreshing token: ${String(t)}`)}}),h.promise().then(()=>{this.log.info(`${e.id} S3 upload complete`),i.close(),clearTimeout(n),this.uploadComplete(r,e).then(()=>{o(e)}).catch(e=>{console.log("catch"),a(e)}).finally(()=>{this.uploadState("progress","decr",{total:e.size,bytes:e.size}),this.uploadsInProgress=this.uploadsInProgress.filter(e=>e!==h)})}).catch(t=>{this.log.warn(`${e.id} uploadStreamError ${t}`),a(t)})})})}async uploadComplete(e,t){this.log.info(`${t.id} uploaded to S3: ${e}`);const i={bucket:this.config.instance.bucket,outputQueue:this.config.instance.outputQueueName,remote_addr:this.config.instance.remote_addr,user_defined:this.config.instance.user_defined||null,apikey:this.config.options.apikey,id_workflow_instance:this.config.instance.id_workflow_instance,id_master:this.config.instance.id_workflow,utc:(new Date).toISOString(),path:e,prefix:e.substring(0,e.lastIndexOf("/"))};if(this.config.instance.chain)try{i.components=JSON.parse(JSON.stringify(this.config.instance.chain.components)),i.targetComponentId=this.config.instance.chain.targetComponentId}catch(r){return this.log.error(`${t.id} exception parsing components JSON ${String(r)}`),Promise.reject(r)}if(this.config.instance.key_id&&(i.key_id=this.config.instance.key_id),this.config.options.agent_address)try{i.agent_address=JSON.parse(this.config.options.agent_address)}catch(n){this.log.error(`${t.id} Could not parse agent_address ${String(n)}`)}i.components&&Object.keys(i.components).forEach(e=>{"uploadMessageQueue"===i.components[e].inputQueueName&&(i.components[e].inputQueueName=this.uploadMessageQueue),"downloadMessageQueue"===i.components[e].inputQueueName&&(i.components[e].inputQueueName=this.downloadMessageQueue)});let o={};try{const e=await this.discoverQueue(this.config.instance.inputQueueName),s=await this.sessionedSQS();this.log.info(`${t.id} sending SQS message to input queue`),o=await s.sendMessage({QueueUrl:e,MessageBody:JSON.stringify(i)}).promise()}catch(a){return this.log.error(`${t.id} exception sending SQS message: ${String(a)}`),Promise.reject(a)}return this.realtimeFeedback("workflow_instance:state",{type:"start",id_workflow_instance:this.config.instance.id_workflow_instance,id_workflow:this.config.instance.id_workflow,component_id:"0",message_id:s(o).MessageId,id_user:this.config.instance.id_user}).catch(e=>{this.log.warn(`realtimeFeedback failed: ${String(e)}`)}),this.log.info(`${t.id} SQS message sent. Mark as uploaded`),this.db.uploadFile(t.path)}async fetchTelemetry(){var e,s;if(!(null===(s=null===(e=this.config)||void 0===e?void 0:e.instance)||void 0===s?void 0:s.summaryTelemetry))return Promise.resolve();const i=g.join(Me(),"instances"),o=g.join(i,this.config.instance.id_workflow_instance),r=[];Object.keys(this.config.instance.summaryTelemetry).forEach(e=>{const s=this.config.instance.summaryTelemetry[e]||{};let i=s[Object.keys(s)[0]];if(!i)return;i.startsWith("http")||(i=L(this.config.options.url,i));const n=g.join(o,`${e}.json`);r.push(this.REST.fetchContent(i).then(e=>(t.writeJSONSync(n,e),this.reportState$.next(!0),this.log.debug(`fetched telemetry summary ${n}`),Promise.resolve(e))).catch(e=>(this.log.debug(`Error fetching telemetry: ${String(e)}`),Promise.resolve(null))))});let n=0;try{const e=await Promise.all(r);this.instanceTelemetry$.next(e)}catch(a){n+=1}return n&&this.log.warn("summary telemetry incomplete"),Promise.resolve()}}Fe.version=le.version,Fe.REST=xe,Fe.utils=le,Fe.SessionManager=Re,Fe.EPI2ME_HOME=Me(),Fe.Profile=Te,Fe.Factory=class{constructor(e,t){this.EPI2ME=e,this.options=t,this.masterInstance=new e(this.options),this.log=this.masterInstance.log,this.REST=this.masterInstance.REST,this.graphQL=this.masterInstance.graphQL,this.SampleReader=this.masterInstance.SampleReader,this.utils=e.utils,this.version=e.version,this.runningInstances={}}async startRun(e,t){const s=new this.EPI2ME(Object.assign(Object.assign({},this.options),e));try{const e=await s.autoStart(t);this.runningInstances[e.id_workflow_instance]=s}catch(i){this.log.error(`Experienced error starting ${String(i)}`);try{await s.stopEverything()}catch(o){this.log.error(`Also experienced error stopping ${String(o)}`)}}return s}async startGQLRun(e,t){const s=new this.EPI2ME(Object.assign(Object.assign(Object.assign({},this.options),e),{useGraphQL:!0}));try{const e=await s.autoStartGQL(t);this.runningInstances[e.id_workflow_instance]=s,console.log(e)}catch(i){this.log.error(`Experienced error starting ${String(i)}`);try{await s.stopEverything()}catch(o){this.log.error(`Also experienced error stopping ${String(o)}`)}}return s}};export default Fe;
